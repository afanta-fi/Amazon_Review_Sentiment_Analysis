{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Business-Understanding\" data-toc-modified-id=\"Business-Understanding-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Business Understanding</a></span></li><li><span><a href=\"#Data-Understanding\" data-toc-modified-id=\"Data-Understanding-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Understanding</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Preparation</a></span></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing-Class\" data-toc-modified-id=\"Preprocessing-Class-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Preprocessing Class</a></span></li><li><span><a href=\"#Grid-Search\" data-toc-modified-id=\"Grid-Search-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Grid Search</a></span></li><li><span><a href=\"#Model-Performance-Visualization\" data-toc-modified-id=\"Model-Performance-Visualization-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Model Performance Visualization</a></span></li><li><span><a href=\"#Shallow-Learning\" data-toc-modified-id=\"Shallow-Learning-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Shallow Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Naive Bayes</a></span></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-4.4.3\"><span class=\"toc-item-num\">4.4.3&nbsp;&nbsp;</span>Random Forest</a></span></li></ul></li><li><span><a href=\"#Gradient-Boosting\" data-toc-modified-id=\"Gradient-Boosting-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Gradient Boosting</a></span><ul class=\"toc-item\"><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>XGBoost</a></span></li><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-4.5.2\"><span class=\"toc-item-num\">4.5.2&nbsp;&nbsp;</span>CatBoost</a></span></li></ul></li><li><span><a href=\"#Sequence-Models\" data-toc-modified-id=\"Sequence-Models-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Sequence Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Long-Short-Term-Memory\" data-toc-modified-id=\"Long-Short-Term-Memory-4.6.1\"><span class=\"toc-item-num\">4.6.1&nbsp;&nbsp;</span>Long Short Term Memory</a></span></li></ul></li><li><span><a href=\"#Transformer-Models\" data-toc-modified-id=\"Transformer-Models-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Transformer Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bidirectional-Encoder-Representations-from-Transformers\" data-toc-modified-id=\"Bidirectional-Encoder-Representations-from-Transformers-4.7.1\"><span class=\"toc-item-num\">4.7.1&nbsp;&nbsp;</span>Bidirectional Encoder Representations from Transformers</a></span></li><li><span><a href=\"#Hugging-Face\" data-toc-modified-id=\"Hugging-Face-4.7.2\"><span class=\"toc-item-num\">4.7.2&nbsp;&nbsp;</span>Hugging Face</a></span></li></ul></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Models'-Performances\" data-toc-modified-id=\"Models'-Performances-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Models' Performances</a></span></li><li><span><a href=\"#Final-Model\" data-toc-modified-id=\"Final-Model-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Final Model</a></span></li><li><span><a href=\"#Model-Interpretation\" data-toc-modified-id=\"Model-Interpretation-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Model Interpretation</a></span></li><li><span><a href=\"#API-Development\" data-toc-modified-id=\"API-Development-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>API Development</a></span></li><li><span><a href=\"#Web-Deployment\" data-toc-modified-id=\"Web-Deployment-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Web Deployment</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusion</a></span></li><li><span><a href=\"#Next-Steps\" data-toc-modified-id=\"Next-Steps-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Next Steps</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyenchant \n",
    "# ! pip install autocorrect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import important libraries\n",
    "import os\n",
    "from os import remove\n",
    "from os.path import exists\n",
    "import wget\n",
    "import zipfile\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import bz2\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "import re \n",
    "from autocorrect import Speller\n",
    "from enchant import request_dict\n",
    "from enchant.checker import SpellChecker\n",
    "from enchant.tokenize import EmailFilter, URLFilter\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.concurrent import process_map \n",
    "from multiprocessing import Pool\n",
    "from time import time\n",
    "import itertools as it\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier \n",
    "from catboost import CatBoostClassifier\n",
    "import tensorflow\n",
    "from tensorflow.python.keras import models, layers, optimizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import shap \n",
    "from sklearn.metrics import precision_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import f1_score,roc_auc_score,log_loss,roc_curve,auc,confusion_matrix\n",
    "import dill as pickle\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "\n",
    "# Enable inline ploting\n",
    "%matplotlib inline \n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\zeaps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zeaps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zeaps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 3600000/3600000 [00:03<00:00, 1052017.19it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_data(b2z_file_loc):\n",
    "    file = bz2.BZ2File(b2z_file_loc)\n",
    "    t = tqdm(file.readlines())\n",
    "    t.set_description('Loading '+b2z_file_loc.split('/')[-1].split('.')[0]+' data')\n",
    "    return [x.decode('utf-8') for x in t]\n",
    "        \n",
    "train_file_lines = load_data('data/train.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n',\n",
       " \"__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\\n\",\n",
       " '__label__2 Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\\n',\n",
       " \"__label__2 Excellent Soundtrack: I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\\n\",\n",
       " \"__label__2 Remember, Pull Your Jaw Off The Floor After Hearing it: If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\\n\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"__label__1 The Worst!: A complete waste of time. Typographical errors, poor grammar, and a totally pathetic plot add up to absolutely nothing. I'm embarrassed for this author and very disappointed I actually paid for this book.\\n\",\n",
       " '__label__2 Great book: This was a great book,I just could not put it down,and could not read it fast enough. Boy what a book the twist and turns in this just keeps you guessing and wanting to know what is going to happen next. This book makes you fall in love and can heat you up,it can also make you so angery. this book can make you go throu several of your emotions. This is a quick read romance. It is something that you will want to end your day off with if you read at night.\\n',\n",
       " '__label__2 Great Read: I thought this book was brilliant, but yet realistic. It showed me that to error is human. I loved the fact that this writer showed the loving side of God and not the revengeful side of him. I loved how it twisted and turned and I could not put it down. I also loved The glass castle.\\n',\n",
       " \"__label__1 Oh please: I guess you have to be a romance novel lover for this one, and not a very discerning one. All others beware! It is absolute drivel. I figured I was in trouble when a typo is prominently featured on the back cover, but the first page of the book removed all doubt. Wait - maybe I'm missing the point. A quick re-read of the beginning now makes it clear. This has to be an intentional churning of over-heated prose for satiric purposes. Phew, so glad I didn't waste $10.95 after all.\\n\",\n",
       " '__label__1 Awful beyond belief!: I feel I have to write to keep others from wasting their money. This book seems to have been written by a 7th grader with poor grammatical skills for her age! As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. For example, it was mentioned twice that she had a \"lean\" on her house. I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. Please don\\'t waste your money. I too, believe that the good reviews must have been written by the author\\'s relatives. I will not put much faith in the reviews from now on!\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_lines[10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Translate nltk POS to wordnet tags\n",
    "    '''\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkr = SpellChecker(\"en_US\",filters=[EmailFilter,URLFilter])\n",
    "spell = Speller(lang='en')\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "tokenizer = RegexpTokenizer(pattern)\n",
    "sw = stopwords.words('english')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def data_cleaner(data, labeled=True):\n",
    "    splits = data.split('__label__')[-1]\n",
    "    if labeled:\n",
    "        labels = int(splits[0])-1    \n",
    "        statement = decontracted(splits[1:].lower())\n",
    "    else:\n",
    "        labels = np.nan\n",
    "        statement = decontracted(splits.lower())\n",
    "    statement = spell(statement)\n",
    "    chkr.set_text(statement)\n",
    "    for err in chkr:\n",
    "        try:            \n",
    "            statement = statement.replace(err.word,request_dict(err.word)[0])\n",
    "        except:\n",
    "            continue\n",
    "    statement = tokenizer.tokenize(statement)        \n",
    "    statement = [w for w in statement if w not in sw]\n",
    "    statement_tagged = [(token[0], get_wordnet_pos(token[1]))\n",
    "                        for token in pos_tag(statement)]\n",
    "    statement_lemmed = [lemmatizer.lemmatize(token[0], token[1]) for token in statement_tagged]\n",
    "    return statement_lemmed, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tune',\n",
       " 'even',\n",
       " 'non',\n",
       " 'gamer',\n",
       " 'sound',\n",
       " 'track',\n",
       " 'beautiful',\n",
       " 'paint',\n",
       " 'scenery',\n",
       " 'mind',\n",
       " 'well',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'even',\n",
       " 'people',\n",
       " 'hate',\n",
       " 'vid',\n",
       " 'game',\n",
       " 'music',\n",
       " 'play',\n",
       " 'game',\n",
       " 'chrono',\n",
       " 'cross',\n",
       " 'game',\n",
       " 'ever',\n",
       " 'play',\n",
       " 'best',\n",
       " 'music',\n",
       " 'back',\n",
       " 'away',\n",
       " 'crude',\n",
       " 'keyboardist',\n",
       " 'take',\n",
       " 'fresh',\n",
       " 'step',\n",
       " 'rate',\n",
       " 'guitar',\n",
       " 'soulful',\n",
       " 'orchestra',\n",
       " 'would',\n",
       " 'impress',\n",
       " 'anyone',\n",
       " 'care',\n",
       " 'listen']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement, labels = data_cleaner(train_file_lines[0])\n",
    "statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(file_lines, attrib):\n",
    "    currtime = time()\n",
    "    results = process_map(data_cleaner, file_lines, \n",
    "                          max_workers=Pool()._processes, \n",
    "                          chunksize=Pool()._processes)\n",
    "    statements = []\n",
    "    labels = []\n",
    "    for result in results:\n",
    "        statements.append(result[0])\n",
    "        labels.append(result[-1])\n",
    "    df = pd.DataFrame(columns=['statements','labels'])\n",
    "    df.statements = statements\n",
    "    df.labels = labels\n",
    "    df.to_csv(r'data/'+attrib+'.zip', index=False, compression='gzip')\n",
    "    print('Parallel: time elapsed:', time() - currtime)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists('data/train.zip'):\n",
    "    del train_file_lines\n",
    "    train_df = pd.read_csv('data/train.zip', compression='gzip')\n",
    "    def str_cleaner(line):\n",
    "        return line[1:-1].replace(\"'\",'').replace(' ','').replace(',',' ')\n",
    "    train_df.statements = train_df.statements.apply(str_cleaner)\n",
    "else:\n",
    "    train_df = save_to_file(train_file_lines, 'train') \n",
    "    del train_file_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statements</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tune even non gamer sound track beautiful pain...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best soundtrack ever anything reading lot revi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amaze soundtrack favorite music time hand inte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excellent soundtrack truly like soundtrack enj...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remember pull jaw floor hear played game know ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          statements  labels\n",
       "0  tune even non gamer sound track beautiful pain...       1\n",
       "1  best soundtrack ever anything reading lot revi...       1\n",
       "2  amaze soundtrack favorite music time hand inte...       1\n",
       "3  excellent soundtrack truly like soundtrack enj...       1\n",
       "4  remember pull jaw floor hear played game know ...       1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.labels.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = FreqDist(tokenizer.tokenize(' '.join(train_df.statements[:100].to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tune': 1,\n",
       " 'even': 19,\n",
       " 'non': 4,\n",
       " 'gamer': 1,\n",
       " 'sound': 9,\n",
       " 'track': 8,\n",
       " 'beautiful': 3,\n",
       " 'paint': 3,\n",
       " 'scenery': 1,\n",
       " 'mind': 3,\n",
       " 'well': 14,\n",
       " 'would': 30,\n",
       " 'recommend': 9,\n",
       " 'people': 7,\n",
       " 'hate': 2,\n",
       " 'vid': 1,\n",
       " 'game': 40,\n",
       " 'music': 22,\n",
       " 'play': 21,\n",
       " 'chrono': 4,\n",
       " 'cross': 4,\n",
       " 'ever': 8,\n",
       " 'best': 15,\n",
       " 'back': 10,\n",
       " 'away': 5,\n",
       " 'crude': 1,\n",
       " 'keyboardist': 1,\n",
       " 'take': 8,\n",
       " 'fresh': 1,\n",
       " 'step': 1,\n",
       " 'rate': 2,\n",
       " 'guitar': 3,\n",
       " 'soulful': 1,\n",
       " 'orchestra': 1,\n",
       " 'impress': 2,\n",
       " 'anyone': 6,\n",
       " 'care': 2,\n",
       " 'listen': 6,\n",
       " 'soundtrack': 12,\n",
       " 'anything': 2,\n",
       " 'reading': 3,\n",
       " 'lot': 7,\n",
       " 'review': 12,\n",
       " 'say': 14,\n",
       " 'figure': 7,\n",
       " 'write': 19,\n",
       " 'disagree': 2,\n",
       " 'bit': 6,\n",
       " 'opinion': 4,\n",
       " 'yasunori': 2,\n",
       " 'mitsuda': 4,\n",
       " 'ultimate': 1,\n",
       " 'masterpiece': 2,\n",
       " 'timeless': 1,\n",
       " 'year': 20,\n",
       " 'beauty': 1,\n",
       " 'simply': 1,\n",
       " 'refuse': 1,\n",
       " 'fade': 2,\n",
       " 'price': 6,\n",
       " 'tag': 1,\n",
       " 'pretty': 8,\n",
       " 'stagger': 1,\n",
       " 'must': 9,\n",
       " 'go': 22,\n",
       " 'buy': 26,\n",
       " 'cd': 15,\n",
       " 'much': 16,\n",
       " 'money': 8,\n",
       " 'one': 42,\n",
       " 'feel': 5,\n",
       " 'worth': 6,\n",
       " 'every': 8,\n",
       " 'penny': 1,\n",
       " 'amaze': 6,\n",
       " 'favorite': 2,\n",
       " 'time': 30,\n",
       " 'hand': 4,\n",
       " 'intense': 1,\n",
       " 'sadness': 1,\n",
       " 'prisoner': 2,\n",
       " 'fate': 2,\n",
       " 'mean': 1,\n",
       " 'played': 3,\n",
       " 'hope': 3,\n",
       " 'distant': 2,\n",
       " 'promise': 2,\n",
       " 'girl': 6,\n",
       " 'stole': 1,\n",
       " 'star': 17,\n",
       " 'important': 2,\n",
       " 'inspiration': 2,\n",
       " 'personally': 1,\n",
       " 'throughout': 1,\n",
       " 'teen': 3,\n",
       " 'higher': 1,\n",
       " 'energy': 2,\n",
       " 'like': 26,\n",
       " 'scar': 4,\n",
       " 'dreamwatch': 1,\n",
       " 'chronomantique': 2,\n",
       " 'indefinably': 1,\n",
       " 'reminiscent': 1,\n",
       " 'trigger': 1,\n",
       " 'absolutely': 3,\n",
       " 'superb': 1,\n",
       " 'probably': 4,\n",
       " 'composer': 1,\n",
       " 'work': 20,\n",
       " 'heard': 3,\n",
       " 'xenogears': 1,\n",
       " 'ca': 14,\n",
       " 'sure': 3,\n",
       " 'never': 12,\n",
       " 'twice': 3,\n",
       " 'wish': 5,\n",
       " 'could': 11,\n",
       " 'give': 10,\n",
       " 'excellent': 9,\n",
       " 'truly': 4,\n",
       " 'enjoy': 6,\n",
       " 'video': 5,\n",
       " 'relaxing': 1,\n",
       " 'peaceful': 1,\n",
       " 'disk': 3,\n",
       " 'favorites': 1,\n",
       " 'life': 7,\n",
       " 'death': 2,\n",
       " 'forest': 1,\n",
       " 'illusion': 1,\n",
       " 'fortress': 1,\n",
       " 'ancient': 2,\n",
       " 'dragon': 5,\n",
       " 'lose': 1,\n",
       " 'fragment': 1,\n",
       " 'drown': 1,\n",
       " 'valley': 1,\n",
       " 'two': 7,\n",
       " 'galore': 1,\n",
       " 'home': 3,\n",
       " 'gale': 1,\n",
       " 'girlfriend': 1,\n",
       " 'zelbessdisk': 1,\n",
       " 'three': 6,\n",
       " 'garden': 1,\n",
       " 'god': 5,\n",
       " 'chronopolis': 1,\n",
       " 'fat': 3,\n",
       " 'jellyfish': 1,\n",
       " 'sea': 4,\n",
       " 'burn': 1,\n",
       " 'orphanage': 1,\n",
       " 'prayer': 1,\n",
       " 'tower': 1,\n",
       " 'radical': 3,\n",
       " 'dreamer': 4,\n",
       " 'unstealable': 1,\n",
       " 'jewel': 2,\n",
       " 'overall': 2,\n",
       " 'bring': 3,\n",
       " 'lander': 1,\n",
       " 'remember': 3,\n",
       " 'pull': 3,\n",
       " 'jaw': 1,\n",
       " 'floor': 1,\n",
       " 'hear': 7,\n",
       " 'know': 11,\n",
       " 'divine': 2,\n",
       " 'single': 4,\n",
       " 'song': 11,\n",
       " 'tell': 6,\n",
       " 'story': 9,\n",
       " 'good': 23,\n",
       " 'great': 30,\n",
       " 'without': 4,\n",
       " 'doubt': 2,\n",
       " 'magical': 1,\n",
       " 'wind': 1,\n",
       " 'steal': 1,\n",
       " 'translation': 1,\n",
       " 'varies': 1,\n",
       " 'perfect': 3,\n",
       " 'ask': 1,\n",
       " 'pour': 1,\n",
       " 'heart': 4,\n",
       " 'paper': 2,\n",
       " 'absolute': 3,\n",
       " 'quite': 4,\n",
       " 'actually': 5,\n",
       " 'read': 27,\n",
       " 'least': 6,\n",
       " 'whether': 3,\n",
       " 'aware': 1,\n",
       " 'contribute': 1,\n",
       " 'greatly': 1,\n",
       " 'mood': 2,\n",
       " 'minute': 2,\n",
       " 'whole': 7,\n",
       " 'compose': 1,\n",
       " 'exact': 1,\n",
       " 'count': 1,\n",
       " 'render': 1,\n",
       " 'impressively': 1,\n",
       " 'remarkable': 1,\n",
       " 'assure': 1,\n",
       " 'forget': 3,\n",
       " 'everything': 5,\n",
       " 'listener': 1,\n",
       " 'fast': 3,\n",
       " 'pace': 1,\n",
       " 'energetic': 1,\n",
       " 'dancing': 1,\n",
       " 'storage': 1,\n",
       " 'terminal': 1,\n",
       " 'slower': 1,\n",
       " 'haunt': 1,\n",
       " 'purely': 1,\n",
       " 'beautifully': 2,\n",
       " 'composed': 1,\n",
       " 'fantastic': 1,\n",
       " 'vocal': 1,\n",
       " 'videogame': 1,\n",
       " 'surely': 1,\n",
       " 'buyer': 3,\n",
       " 'beware': 5,\n",
       " 'self': 1,\n",
       " 'publish': 1,\n",
       " 'book': 58,\n",
       " 'want': 17,\n",
       " 'paragraphs': 1,\n",
       " 'ms': 1,\n",
       " 'hidden': 3,\n",
       " 'family': 5,\n",
       " 'friends': 1,\n",
       " 'perhaps': 3,\n",
       " 'imagine': 1,\n",
       " 'thing': 11,\n",
       " 'spend': 3,\n",
       " 'friend': 2,\n",
       " 'mystery': 2,\n",
       " 'piece': 3,\n",
       " 'another': 10,\n",
       " 'definitely': 2,\n",
       " 'bad': 12,\n",
       " 'enough': 7,\n",
       " 'enter': 2,\n",
       " 'kind': 4,\n",
       " 'contest': 1,\n",
       " 'believe': 5,\n",
       " 'amazon': 8,\n",
       " 'sell': 2,\n",
       " 'maybe': 4,\n",
       " 'offer': 1,\n",
       " 'th': 2,\n",
       " 'grade': 2,\n",
       " 'term': 1,\n",
       " 'kill': 1,\n",
       " 'mockingbird': 1,\n",
       " 'm': 1,\n",
       " 'anyway': 2,\n",
       " 'unless': 3,\n",
       " 'send': 4,\n",
       " 'someone': 3,\n",
       " 'joke': 1,\n",
       " 'stay': 5,\n",
       " 'far': 2,\n",
       " 'glorious': 1,\n",
       " 'love': 33,\n",
       " 'whisper': 3,\n",
       " 'wicked': 3,\n",
       " 'saint': 3,\n",
       " 'pleasant': 1,\n",
       " 'surprise': 3,\n",
       " 'change': 1,\n",
       " 'normal': 1,\n",
       " 'romance': 6,\n",
       " 'novels': 1,\n",
       " 'world': 3,\n",
       " 'brilliant': 2,\n",
       " 'true': 5,\n",
       " 'wonderful': 3,\n",
       " 'told': 1,\n",
       " 'typical': 1,\n",
       " 'crime': 1,\n",
       " 'becuase': 1,\n",
       " 'miss': 4,\n",
       " 'warm': 3,\n",
       " 'five': 2,\n",
       " 'finish': 3,\n",
       " 'fell': 1,\n",
       " 'character': 1,\n",
       " 'expect': 8,\n",
       " 'average': 1,\n",
       " 'instead': 3,\n",
       " 'find': 18,\n",
       " 'think': 13,\n",
       " 'predict': 1,\n",
       " 'outcome': 1,\n",
       " 'shocked': 1,\n",
       " 'descriptive': 1,\n",
       " 'break': 2,\n",
       " 'julia': 1,\n",
       " 'felt': 3,\n",
       " 'reader': 1,\n",
       " 'lover': 2,\n",
       " 'novel': 2,\n",
       " 'let': 6,\n",
       " 'cover': 4,\n",
       " 'fool': 2,\n",
       " 'spectacular': 1,\n",
       " 'easy': 6,\n",
       " 'make': 28,\n",
       " 'keep': 10,\n",
       " 'put': 7,\n",
       " 'left': 1,\n",
       " 'wanting': 1,\n",
       " 'follow': 2,\n",
       " 'come': 13,\n",
       " 'soon': 5,\n",
       " 'use': 17,\n",
       " 'get': 38,\n",
       " 'enjoyable': 2,\n",
       " 'complete': 5,\n",
       " 'waste': 6,\n",
       " 'typographical': 1,\n",
       " 'error': 2,\n",
       " 'poor': 6,\n",
       " 'grammar': 2,\n",
       " 'totally': 3,\n",
       " 'pathetic': 1,\n",
       " 'plot': 3,\n",
       " 'add': 2,\n",
       " 'nothing': 7,\n",
       " 'embarrass': 1,\n",
       " 'author': 5,\n",
       " 'disappoint': 3,\n",
       " 'pay': 3,\n",
       " 'boy': 2,\n",
       " 'twist': 1,\n",
       " 'turn': 5,\n",
       " 'guess': 6,\n",
       " 'happen': 5,\n",
       " 'next': 3,\n",
       " 'fall': 2,\n",
       " 'heat': 2,\n",
       " 'also': 12,\n",
       " 'angry': 1,\n",
       " 'throw': 3,\n",
       " 'several': 3,\n",
       " 'emotion': 1,\n",
       " 'quick': 3,\n",
       " 'something': 5,\n",
       " 'end': 5,\n",
       " 'day': 8,\n",
       " 'night': 3,\n",
       " 'yet': 3,\n",
       " 'realistic': 1,\n",
       " 'show': 9,\n",
       " 'human': 3,\n",
       " 'fact': 3,\n",
       " 'writer': 1,\n",
       " 'loving': 1,\n",
       " 'side': 2,\n",
       " 'vengeful': 1,\n",
       " 'twisted': 1,\n",
       " 'glass': 1,\n",
       " 'castle': 6,\n",
       " 'oh': 2,\n",
       " 'please': 3,\n",
       " 'discard': 1,\n",
       " 'others': 3,\n",
       " 'driver': 1,\n",
       " 'trouble': 2,\n",
       " 'typo': 1,\n",
       " 'prominently': 1,\n",
       " 'feature': 4,\n",
       " 'first': 9,\n",
       " 'page': 3,\n",
       " 'remove': 2,\n",
       " 'wait': 3,\n",
       " 'point': 4,\n",
       " 'begin': 5,\n",
       " 'clear': 4,\n",
       " 'intentional': 1,\n",
       " 'turning': 1,\n",
       " 'prose': 1,\n",
       " 'satirical': 1,\n",
       " 'purpose': 1,\n",
       " 'chew': 2,\n",
       " 'glad': 2,\n",
       " 'awful': 2,\n",
       " 'beyond': 1,\n",
       " 'belief': 1,\n",
       " 'seem': 6,\n",
       " 'grader': 1,\n",
       " 'grammatical': 1,\n",
       " 'skill': 1,\n",
       " 'age': 5,\n",
       " 'reviewer': 3,\n",
       " 'misspell': 1,\n",
       " 'per': 1,\n",
       " 'chapter': 1,\n",
       " 'example': 1,\n",
       " 'mention': 1,\n",
       " 'lean': 1,\n",
       " 'house': 2,\n",
       " 'distract': 1,\n",
       " 'weak': 1,\n",
       " 'decide': 5,\n",
       " 'pencil': 1,\n",
       " 'mark': 1,\n",
       " 'horrible': 2,\n",
       " 'spell': 1,\n",
       " 'relatives': 1,\n",
       " 'faith': 1,\n",
       " 'try': 5,\n",
       " 'u': 4,\n",
       " 'fake': 1,\n",
       " 'sparingly': 1,\n",
       " 'obvious': 1,\n",
       " 'glow': 1,\n",
       " 'person': 4,\n",
       " 'misspelling': 1,\n",
       " 'sentence': 1,\n",
       " 'structure': 1,\n",
       " 'veronica': 1,\n",
       " 'romantic': 1,\n",
       " 'zen': 2,\n",
       " 'baseball': 1,\n",
       " 'comedy': 2,\n",
       " 'folk': 1,\n",
       " 'em': 1,\n",
       " 'anymore': 3,\n",
       " 'might': 3,\n",
       " 'talk': 2,\n",
       " 'cool': 2,\n",
       " 'young': 6,\n",
       " 'cuban': 1,\n",
       " 'search': 1,\n",
       " 'identity': 1,\n",
       " 'stumble': 1,\n",
       " 'coastal': 1,\n",
       " 'resort': 2,\n",
       " 'kitchen': 5,\n",
       " 'gig': 1,\n",
       " 'motorcycle': 1,\n",
       " 'maintenance': 1,\n",
       " 'man': 4,\n",
       " 'hysterical': 1,\n",
       " 'italian': 1,\n",
       " 'chef': 1,\n",
       " 'latino': 1,\n",
       " 'fireballing': 1,\n",
       " 'right': 7,\n",
       " 'pitcher': 1,\n",
       " 'team': 1,\n",
       " 'sponsor': 1,\n",
       " 'owner': 1,\n",
       " 'often': 2,\n",
       " 'case': 1,\n",
       " 'honest': 1,\n",
       " 'comical': 1,\n",
       " 'always': 8,\n",
       " 'emotional': 1,\n",
       " 'interaction': 2,\n",
       " 'sibling': 1,\n",
       " 'roster': 1,\n",
       " 'player': 11,\n",
       " 'mix': 10,\n",
       " 'special': 1,\n",
       " 'effect': 1,\n",
       " 'salsa': 2,\n",
       " 'flashback': 1,\n",
       " 'big': 10,\n",
       " 'fashionable': 1,\n",
       " 'compression': 4,\n",
       " 'stocking': 6,\n",
       " 'dot': 1,\n",
       " 'doctor': 1,\n",
       " 'require': 2,\n",
       " 'wear': 7,\n",
       " 'ugly': 1,\n",
       " 'white': 3,\n",
       " 'ted': 1,\n",
       " 'hose': 1,\n",
       " 'lucky': 1,\n",
       " 'thick': 1,\n",
       " 'brown': 1,\n",
       " 'job': 5,\n",
       " 'ultrasheer': 3,\n",
       " 'need': 6,\n",
       " 'look': 14,\n",
       " 'regular': 1,\n",
       " 'pantyhose': 1,\n",
       " 'though': 2,\n",
       " 'blood': 1,\n",
       " 'clot': 1,\n",
       " 'still': 8,\n",
       " 'support': 3,\n",
       " 'legs': 1,\n",
       " 'nice': 6,\n",
       " 'note': 1,\n",
       " 'problem': 8,\n",
       " 'rubberize': 1,\n",
       " 'top': 5,\n",
       " 'roll': 4,\n",
       " 'thigh': 2,\n",
       " 'adhesive': 1,\n",
       " 'hat': 1,\n",
       " 'skin': 2,\n",
       " 'inexpensive': 1,\n",
       " 'carter': 1,\n",
       " 'belt': 1,\n",
       " 'fine': 5,\n",
       " 'help': 6,\n",
       " 'high': 2,\n",
       " 'product': 3,\n",
       " 'however': 8,\n",
       " 'difficult': 1,\n",
       " 'old': 19,\n",
       " 'full': 6,\n",
       " 'workout': 1,\n",
       " 'create': 3,\n",
       " 'deep': 1,\n",
       " 'ridge': 1,\n",
       " 'difficulty': 1,\n",
       " 'address': 1,\n",
       " 'size': 4,\n",
       " 'chart': 2,\n",
       " 'real': 7,\n",
       " 'small': 5,\n",
       " 'sheer': 3,\n",
       " 'item': 2,\n",
       " 'internet': 1,\n",
       " 'store': 4,\n",
       " 'check': 4,\n",
       " 'men': 1,\n",
       " 'model': 3,\n",
       " 'may': 3,\n",
       " 'ok': 2,\n",
       " 'sedentary': 1,\n",
       " 'type': 1,\n",
       " 'active': 1,\n",
       " 'around': 8,\n",
       " 'alot': 2,\n",
       " 'consistently': 1,\n",
       " 'ankle': 1,\n",
       " 'solution': 1,\n",
       " 'standard': 4,\n",
       " 'stock': 2,\n",
       " 'pair': 4,\n",
       " 'tore': 1,\n",
       " 'struggled': 1,\n",
       " 'riddance': 1,\n",
       " 'investment': 1,\n",
       " 'delicious': 1,\n",
       " 'cookie': 5,\n",
       " 'funny': 2,\n",
       " 'header': 1,\n",
       " 'quickly': 2,\n",
       " 'package': 5,\n",
       " 'cooky': 2,\n",
       " 'notice': 4,\n",
       " 'since': 9,\n",
       " 'title': 5,\n",
       " 'bake': 2,\n",
       " 'convenience': 1,\n",
       " 'dough': 2,\n",
       " 'wrap': 2,\n",
       " 'plastic': 3,\n",
       " 'log': 2,\n",
       " 'bite': 1,\n",
       " 'messy': 1,\n",
       " 'extremely': 2,\n",
       " 'sticky': 1,\n",
       " 'flexibility': 1,\n",
       " 'ratio': 1,\n",
       " 'ingredient': 2,\n",
       " 'extra': 1,\n",
       " 'butter': 1,\n",
       " 'baked': 1,\n",
       " 'really': 8,\n",
       " 'large': 2,\n",
       " 'chocolate': 1,\n",
       " 'chip': 1,\n",
       " 'addition': 1,\n",
       " 'natural': 1,\n",
       " 'flavor': 1,\n",
       " 'absmag': 1,\n",
       " 'digital': 1,\n",
       " 'copy': 3,\n",
       " 'rather': 3,\n",
       " 'scratch': 2,\n",
       " 'insect': 1,\n",
       " 'drop': 1,\n",
       " 'random': 1,\n",
       " 'pixelations': 1,\n",
       " 'combine': 1,\n",
       " 'muddy': 1,\n",
       " 'light': 9,\n",
       " 'vague': 1,\n",
       " 'image': 1,\n",
       " 'resolution': 1,\n",
       " 'cue': 1,\n",
       " 'straight': 1,\n",
       " 'street': 1,\n",
       " 'corner': 1,\n",
       " 'bootleg': 2,\n",
       " 'dealer': 1,\n",
       " 'see': 9,\n",
       " 'reasonably': 1,\n",
       " 'condition': 1,\n",
       " 'film': 4,\n",
       " 'define': 1,\n",
       " 'visuals': 2,\n",
       " 'crystal': 1,\n",
       " 'contrast': 1,\n",
       " 'black': 1,\n",
       " 'surround': 2,\n",
       " 'countryside': 1,\n",
       " 'scene': 3,\n",
       " 'set': 8,\n",
       " 'early': 3,\n",
       " 'morning': 1,\n",
       " 'ground': 1,\n",
       " 'list': 3,\n",
       " 'haze': 1,\n",
       " 'memory': 2,\n",
       " 'event': 1,\n",
       " 'bridge': 1,\n",
       " 'water': 1,\n",
       " 'bright': 1,\n",
       " 'immediate': 1,\n",
       " 'dull': 4,\n",
       " 'dark': 1,\n",
       " 'cloud': 1,\n",
       " 'timbre': 1,\n",
       " 'renunciation': 1,\n",
       " 'captain': 1,\n",
       " 'command': 1,\n",
       " 'hard': 6,\n",
       " 'award': 1,\n",
       " 'win': 2,\n",
       " 'critically': 1,\n",
       " 'acclaim': 1,\n",
       " 'presentation': 1,\n",
       " 'youtube': 2,\n",
       " 'somewhere': 2,\n",
       " 'dvd': 24,\n",
       " 'mm': 1,\n",
       " 'public': 2,\n",
       " 'library': 3,\n",
       " 'reel': 1,\n",
       " 'none': 4,\n",
       " 'appear': 1,\n",
       " 'fascinate': 1,\n",
       " 'insight': 1,\n",
       " 'modern': 2,\n",
       " 'japanese': 3,\n",
       " 'thoroughly': 2,\n",
       " 'rise': 2,\n",
       " 'son': 5,\n",
       " 'daughter': 11,\n",
       " 'society': 1,\n",
       " 'view': 4,\n",
       " 'poise': 1,\n",
       " 'parent': 2,\n",
       " 'culture': 4,\n",
       " 'restraint': 1,\n",
       " 'obedience': 1,\n",
       " 'community': 2,\n",
       " 'peer': 1,\n",
       " 'education': 1,\n",
       " 'western': 1,\n",
       " 'form': 1,\n",
       " 'new': 8,\n",
       " 'japan': 2,\n",
       " 'international': 1,\n",
       " 'blend': 1,\n",
       " 'demonstrate': 1,\n",
       " 'vignette': 2,\n",
       " 'private': 1,\n",
       " 'member': 1,\n",
       " 'steven': 1,\n",
       " 'warden': 1,\n",
       " 'clearly': 2,\n",
       " 'talented': 1,\n",
       " 'adopt': 1,\n",
       " 'school': 2,\n",
       " 'four': 5,\n",
       " 'thus': 1,\n",
       " 'able': 2,\n",
       " 'inside': 2,\n",
       " 'album': 7,\n",
       " 'thought': 2,\n",
       " 'blue': 1,\n",
       " 'angel': 1,\n",
       " 'anna': 1,\n",
       " 'mama': 1,\n",
       " 'hair': 1,\n",
       " 'neck': 2,\n",
       " 'roy': 1,\n",
       " 'amazing': 1,\n",
       " 'singer': 1,\n",
       " 'talent': 1,\n",
       " 'charge': 8,\n",
       " 'aaa': 3,\n",
       " 'charger': 5,\n",
       " 'aa': 3,\n",
       " 'battery': 8,\n",
       " 'huge': 1,\n",
       " 'secure': 1,\n",
       " 'flip': 3,\n",
       " 'little': 8,\n",
       " 'button': 5,\n",
       " 'positive': 2,\n",
       " 'pop': 1,\n",
       " 'wo': 5,\n",
       " 'hold': 3,\n",
       " 'mechanism': 1,\n",
       " 'become': 2,\n",
       " 'loose': 1,\n",
       " 'horizontal': 2,\n",
       " 'pressure': 1,\n",
       " 'push': 1,\n",
       " 'duct': 1,\n",
       " 'tape': 2,\n",
       " 'segment': 2,\n",
       " 'crayon': 2,\n",
       " 'apply': 2,\n",
       " 'painful': 1,\n",
       " 'advertise': 1,\n",
       " 'instruction': 6,\n",
       " 'dont': 1,\n",
       " 'do': 3,\n",
       " 'hour': 5,\n",
       " 'return': 8,\n",
       " 'unit': 3,\n",
       " 'useless': 1,\n",
       " 'backup': 1,\n",
       " 'manage': 1,\n",
       " 'drain': 1,\n",
       " 'purchase': 9,\n",
       " 'disappointed': 6,\n",
       " 'convenient': 1,\n",
       " 'last': 5,\n",
       " 'short': 2,\n",
       " 'long': 4,\n",
       " 'koda': 1,\n",
       " 'nimo': 1,\n",
       " 'dear': 1,\n",
       " 'excite': 2,\n",
       " 'ostensibly': 1,\n",
       " 'muslim': 4,\n",
       " 'feminism': 1,\n",
       " 'volume': 2,\n",
       " 'live': 5,\n",
       " 'expectation': 2,\n",
       " 'essay': 2,\n",
       " 'among': 2,\n",
       " 'describes': 1,\n",
       " 'veil': 1,\n",
       " 'potentially': 1,\n",
       " 'liberate': 1,\n",
       " 'explain': 2,\n",
       " 'woman': 2,\n",
       " 'cape': 1,\n",
       " 'town': 1,\n",
       " 'claim': 4,\n",
       " 'separate': 1,\n",
       " 'equal': 1,\n",
       " 'gee': 1,\n",
       " 'whip': 1,\n",
       " 'disappointment': 2,\n",
       " 'hop': 3,\n",
       " 'feminist': 1,\n",
       " 'condemnation': 1,\n",
       " 'gender': 1,\n",
       " 'apartheid': 1,\n",
       " 'enrol': 1,\n",
       " 'virtue': 1,\n",
       " 'female': 1,\n",
       " 'genital': 1,\n",
       " 'mutilation': 1,\n",
       " 'alaska': 5,\n",
       " 'base': 2,\n",
       " 'var': 5,\n",
       " 'christmas': 1,\n",
       " 'present': 1,\n",
       " 'join': 1,\n",
       " 'rest': 3,\n",
       " 'land': 1,\n",
       " 'vhs': 3,\n",
       " 'movie': 14,\n",
       " 'reviews': 1,\n",
       " 'jc': 4,\n",
       " 'tv': 14,\n",
       " 'choice': 4,\n",
       " 'agree': 1,\n",
       " 'awkward': 2,\n",
       " 'selection': 1,\n",
       " 'option': 3,\n",
       " 'hang': 1,\n",
       " 'comment': 1,\n",
       " 'intuitive': 1,\n",
       " 'complicate': 1,\n",
       " 'many': 5,\n",
       " 'remote': 7,\n",
       " 'technically': 1,\n",
       " 'rely': 1,\n",
       " 'heavily': 1,\n",
       " 'manual': 1,\n",
       " 'timer': 1,\n",
       " 'start': 6,\n",
       " 'scroll': 1,\n",
       " 'complaint': 2,\n",
       " 'incorrect': 2,\n",
       " 'disc': 3,\n",
       " 'fan': 2,\n",
       " 'suspicious': 1,\n",
       " 'saw': 2,\n",
       " 'section': 1,\n",
       " 'happy': 5,\n",
       " 'click': 3,\n",
       " 'receiver': 1,\n",
       " 'transition': 1,\n",
       " 'smooth': 1,\n",
       " 'pause': 1,\n",
       " 'fairly': 1,\n",
       " 'headcleaner': 1,\n",
       " 'message': 1,\n",
       " 'nut': 1,\n",
       " 'television': 1,\n",
       " 'bookshelf': 1,\n",
       " 'audio': 6,\n",
       " 'system': 4,\n",
       " 'car': 2,\n",
       " 'move': 4,\n",
       " 'boys': 3,\n",
       " 'room': 7,\n",
       " 'decided': 1,\n",
       " 'combo': 2,\n",
       " 'longer': 1,\n",
       " 'except': 2,\n",
       " 'cable': 4,\n",
       " 'box': 5,\n",
       " 'compatibility': 1,\n",
       " 'control': 5,\n",
       " 'seperate': 1,\n",
       " 'input': 4,\n",
       " 'coat': 1,\n",
       " 'program': 4,\n",
       " 'mono': 1,\n",
       " 'wife': 3,\n",
       " 'difference': 1,\n",
       " 'hollywood': 1,\n",
       " 'debacle': 1,\n",
       " 'ridiculous': 2,\n",
       " 'wonder': 3,\n",
       " 'script': 1,\n",
       " 'mountain': 2,\n",
       " 'lion': 2,\n",
       " 'trailer': 1,\n",
       " 'behind': 3,\n",
       " 'capture': 1,\n",
       " 'jail': 1,\n",
       " 'cell': 1,\n",
       " 'utterly': 1,\n",
       " 'completely': 2,\n",
       " 'stupid': 1,\n",
       " 'bet': 2,\n",
       " 'hotel': 6,\n",
       " 'baryon': 2,\n",
       " 'incredible': 1,\n",
       " 'act': 1,\n",
       " 'tamil': 1,\n",
       " 'outhwaite': 1,\n",
       " 'formerly': 1,\n",
       " 'eastenders': 1,\n",
       " 'bbc': 4,\n",
       " 'soap': 2,\n",
       " 'max': 1,\n",
       " 'beetle': 1,\n",
       " 'ill': 1,\n",
       " 'glitter': 1,\n",
       " 'mariah': 1,\n",
       " 'carey': 1,\n",
       " 'drama': 2,\n",
       " 'series': 2,\n",
       " 'opera': 1,\n",
       " 'mixed': 1,\n",
       " 'air': 5,\n",
       " 'america': 1,\n",
       " 'got': 1,\n",
       " 'episode': 1,\n",
       " 'season': 1,\n",
       " 'finale': 1,\n",
       " 'interesting': 1,\n",
       " 'watch': 3,\n",
       " 'remind': 1,\n",
       " 'abc': 1,\n",
       " 'reason': 1,\n",
       " 'fictional': 1,\n",
       " 'san': 2,\n",
       " 'francisco': 1,\n",
       " 'luxury': 1,\n",
       " 'england': 1,\n",
       " 'willing': 1,\n",
       " 'already': 3,\n",
       " 'casually': 1,\n",
       " 'law': 1,\n",
       " 'seriously': 1,\n",
       " 'unfortunately': 2,\n",
       " 'entertain': 2,\n",
       " 'order': 9,\n",
       " 'hip': 1,\n",
       " 'daddy': 1,\n",
       " 'vibe': 2,\n",
       " 'dismay': 1,\n",
       " 'fourth': 1,\n",
       " 'class': 1,\n",
       " 'main': 1,\n",
       " 'xylaphone': 1,\n",
       " 'playing': 2,\n",
       " 'voice': 4,\n",
       " 'replicate': 1,\n",
       " 'party': 2,\n",
       " 'anywhere': 2,\n",
       " 'neighborhood': 1,\n",
       " 'laughed': 1,\n",
       " 'beach': 1,\n",
       " 'grow': 2,\n",
       " 'surfer': 2,\n",
       " 'diego': 1,\n",
       " 'southern': 3,\n",
       " 'california': 1,\n",
       " 'brother': 2,\n",
       " 'honestly': 1,\n",
       " 'kinda': 1,\n",
       " 'b': 1,\n",
       " 'epitome': 1,\n",
       " 'surf': 1,\n",
       " 'cha': 3,\n",
       " 'michelle': 1,\n",
       " 'hell': 1,\n",
       " 'moral': 1,\n",
       " 'aspect': 1,\n",
       " 'american': 2,\n",
       " 'lucid': 1,\n",
       " 'argue': 2,\n",
       " 'explanation': 1,\n",
       " 'simple': 2,\n",
       " 'focused': 1,\n",
       " 'individual': 1,\n",
       " 'ignore': 2,\n",
       " 'mock': 1,\n",
       " 'personal': 1,\n",
       " 'responsibility': 1,\n",
       " 'final': 1,\n",
       " 'response': 4,\n",
       " 'indictment': 1,\n",
       " 'robert': 1,\n",
       " 'ringer': 1,\n",
       " 'seller': 8,\n",
       " 'disgust': 1,\n",
       " 'foolish': 1,\n",
       " 'state': 2,\n",
       " 'medium': 1,\n",
       " 'politics': 1,\n",
       " 'discourse': 1,\n",
       " 'general': 1,\n",
       " 'head': 3,\n",
       " 'substantial': 1,\n",
       " 'challenge': 2,\n",
       " 'lie': 1,\n",
       " 'americans': 1,\n",
       " 'being': 1,\n",
       " 'larry': 3,\n",
       " 'muse': 1,\n",
       " 'label': 3,\n",
       " 'late': 3,\n",
       " 'explore': 2,\n",
       " 'rich': 2,\n",
       " 'catalog': 1,\n",
       " 'jazz': 1,\n",
       " 'musician': 2,\n",
       " 'relax': 1,\n",
       " 'focus': 1,\n",
       " 'valentine': 1,\n",
       " 'stand': 2,\n",
       " 'chet': 1,\n",
       " 'baker': 2,\n",
       " 'mile': 1,\n",
       " 'mac': 4,\n",
       " 'line': 2,\n",
       " 'os': 3,\n",
       " 'window': 1,\n",
       " 'frustrate': 2,\n",
       " 'attempt': 2,\n",
       " 'touch': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists('glove_embedding.pickle'):\n",
    "    if not exists('glove.6B.300d.txt'):\n",
    "        wget.download(url='https://nlp.stanford.edu/data/glove.6B.zip')\n",
    "        zip_ = zipfile.ZipFile('glove.6B.zip')\n",
    "        zip_.extract('glove.6B.300d.txt')    \n",
    "        zip_.close()    \n",
    "        remove('glove.6B.zip')        \n",
    "    embeddings_index = {}\n",
    "    f = open('glove.6B.300d.txt', encoding = \"utf-8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    remove('glove.6B.300d.txt')\n",
    "    # Save embedding dict to file\n",
    "    with open('glove_embedding.pickle', 'wb') as f:    \n",
    "        pickle.dump(embeddings_index, f)   \n",
    "else:\n",
    "    with open('glove_embedding.pickle', 'rb') as f:    \n",
    "        embeddings_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df.statements, \n",
    "                                                      train_df.labels,\n",
    "                                                      random_state=SEED, \n",
    "                                                      stratify = train_df.labels,\n",
    "                                                      test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "    def __init__(self, dataset=None, \n",
    "                 transformer='tfidf', \n",
    "                 cleaned=True, \n",
    "                 ngram_range=(1,1),\n",
    "                 max_features = 20000,\n",
    "                 min_df = 0.05, \n",
    "                 max_df = 0.95):\n",
    "        self.dataset = dataset\n",
    "        self.transformer = transformer\n",
    "        self.cleaned = cleaned\n",
    "        self.ngram_range = ngram_range\n",
    "        self.max_features = max_features\n",
    "        self.min_df = min_df\n",
    "        self.max_df = max_df\n",
    "    \n",
    "    def load_data(self, n_pool, labeled, attrib):\n",
    "        if not self.cleaned:\n",
    "            statements = []\n",
    "            labels = []\n",
    "            if n_pool==1:\n",
    "                for data in self.dataset:\n",
    "                    statement, label = data_cleaner(data)\n",
    "                    statements.append(statement)\n",
    "                    labels.append(label)\n",
    "            else:\n",
    "                results = process_map(data_cleaner, data, \n",
    "                          max_workers=n_pool, \n",
    "                          chunksize=n_pool)\n",
    "                for result in results:\n",
    "                    statements.append(result[0])\n",
    "                    labels.append(result[-1])\n",
    "            df = pd.DataFrame(columns=['statements','labels'])\n",
    "            df.statements = statements\n",
    "            df.labels = labels\n",
    "            df.to_csv(r'data/'+attrib+'.zip', index=False, compression='gzip')            \n",
    "        else:\n",
    "            df = pd.read_csv('data/'+attrib+'.zip', compression='gzip')\n",
    "            def str_cleaner(line):\n",
    "                return line[1:-1].replace(\"'\",'').replace(' ','').replace(',',' ')\n",
    "            df.statements = df.statements.apply(str_cleaner)\n",
    "        return df\n",
    "    \n",
    "    def transform(self, df):\n",
    "        if self.transformer=='tfidf':\n",
    "            vectorizer = TfidfVectorizer(max_features=self.max_features, \n",
    "                                         ngram_range=self.ngram_range,\n",
    "                                         min_df=self.min_df,\n",
    "                                         max_df=self.max_df)\n",
    "            tokens = vectorizer.fit_transform(df).toarray()\n",
    "        elif self.transformer=='count':\n",
    "            vectorizer = CountVectorizer(max_features=self.max_features, \n",
    "                                         ngram_range=self.ngram_range,\n",
    "                                         min_df=self.min_df,\n",
    "                                         max_df=self.max_df)\n",
    "            tokens = vectorizer.fit_transform(df).toarray()\n",
    "        elif self.transformer=='embed':\n",
    "            def sent2vec(s):\n",
    "                M = []                \n",
    "                for w in s:\n",
    "                    try:\n",
    "                        M.append(embeddings_index[w])\n",
    "                    except:\n",
    "                        continue\n",
    "                M = np.array(M)\n",
    "                v = M.sum(axis=0)\n",
    "                if type(v) != np.ndarray:\n",
    "                    return np.zeros(300)\n",
    "                return v / np.sqrt((v ** 2).sum())\n",
    "            data = df.apply(word_tokenize)\n",
    "            tokens = np.array(data.apply(sent2vec).tolist())\n",
    "        return tokens        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists('train_vec.pickle'):\n",
    "\n",
    "    prep = Preprocess(transformer='tfidf',max_df=0.979,min_df=0.0201)\n",
    "    X_train_tfidf = prep.transform(X_train)\n",
    "\n",
    "    prep = Preprocess(transformer='count',max_df=0.979,min_df=0.0201)\n",
    "    X_train_count = prep.transform(X_train)\n",
    "\n",
    "    prep = Preprocess(transformer='embed')\n",
    "    X_train_embed = prep.transform(X_train)\n",
    "    \n",
    "    X_train_vec = [X_train_tfidf, X_train_count, X_train_embed]\n",
    "    vec_labels = ['TfIdf', 'Count', 'Embedding']\n",
    "    \n",
    "    del X_train_tfidf, X_train_count, X_train_embed\n",
    "    \n",
    "    # Save models to file\n",
    "    with open('train_vec.pickle', 'wb') as f:    \n",
    "        pickle.dump(X_train_vec, f)\n",
    "        pickle.dump(vec_labels, f)\n",
    "        pickle.dump(y_train, f)\n",
    "else:    \n",
    "    # Load models \n",
    "    with open('train_vec.pickle', 'rb') as f:\n",
    "        X_train_vec = pickle.load(f)\n",
    "        vec_labels = pickle.load(f)\n",
    "        y_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs in the system: 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_cpu = os.cpu_count()-1\n",
    "print(\"Number of CPUs in the system:\", n_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_GridSearchCV():\n",
    "    def __init__(self, estimator, param_grid={}, cv=5):\n",
    "        \"\"\"\n",
    "        Custom_GridSearchCV: A grid search that automatically returns\n",
    "        various metrics for almost all sklearn, xgboost and catboost \n",
    "        classification models.\n",
    "        estimator: A string of the model\n",
    "        param_grid: parametric grid for grid search. All entries should be in \n",
    "        string format\n",
    "        cv: Number of cross validation folds \n",
    "        \"\"\"\n",
    "        # Initialize cv\n",
    "        self.cv = cv \n",
    "        # Initialize fitted, boolean if the grid of models have been fitted\n",
    "        self.fitted = False \n",
    "        # Initialize models list\n",
    "        self.models = []\n",
    "        # Initialize cross validation evaluations \n",
    "        self.cross_eval = {}\n",
    "        # Extract parameters for baseline model. Parameters with only one value\n",
    "        # are selected.\n",
    "        base_params = [k+\"=\"+v[0] for k,v in param_grid.items() if len(v)==1]\n",
    "        base_params = ','.join(base_params)\n",
    "        # Initialize baseline model \n",
    "        exec(\"self.baseline_model = \"+estimator+\"(\"+base_params+\")\")\n",
    "        # Create a combinations of the parameter grid \n",
    "        all_params = sorted(param_grid)\n",
    "        combinations = it.product(*(param_grid[name] for name in all_params))\n",
    "        # Iterate through the combinations and keys to create a list of models\n",
    "        keys = list(param_grid.keys())\n",
    "        for j, comb in enumerate(combinations):\n",
    "            params = \"\"\n",
    "            for i, key in enumerate(keys):\n",
    "                params += key+\"=\"+comb[i]+\",\"\n",
    "            # Append models \n",
    "            exec(\"self.models.append(\"+estimator+\"(\"+params[:-1]+\"))\")\n",
    "        # Initialize predictions dataframe\n",
    "        self.predictions = None\n",
    "        self.best_model_ = None \n",
    "            \n",
    "    def cross_validate(self, X, y, scoring=\"accuracy\", vectorization=None):\n",
    "        \"\"\"\n",
    "        Cross validate data on training data and return dataset with the \n",
    "        largest scoring.\n",
    "        X: A list containing different vectorized training datasets \n",
    "        y: Training labels \n",
    "        scoring: The type of scoring used in cross validation. Valid entries \n",
    "        are 'accuracy','precision','recall','f1' and 'roc_auc'\n",
    "        vectorization: User specified corpus vectorization labels to serve \n",
    "        as indices of report dataframe \n",
    "        \"\"\"\n",
    "        # Set default scoring \n",
    "        self.scoring = scoring\n",
    "        # Weighted boolean\n",
    "        weighted = False\n",
    "        # Cross validation: run custom_cross_validate   \n",
    "        if self.cross_eval=={}:            \n",
    "            for i in range(len(X)):\n",
    "                # Convert to dataframe \n",
    "                X[i] = pd.DataFrame(X[i])\n",
    "                # Run custom cross validate on each vectorizatized data   \n",
    "                train_dict, valid_dict = custom_cross_validate(self.baseline_model, \n",
    "                                                               X[i],\n",
    "                                                               y,\n",
    "                                                               cv=self.cv)\n",
    "                # Append values \n",
    "                self.cross_eval[vectorization[i]] = {'train':train_dict,\n",
    "                                               'cross_validate':valid_dict} \n",
    "        # 'return_report' returns values from 'cross_eval' and 'scoring' \n",
    "        return_report = {}        \n",
    "        for dataset in self.cross_eval.keys():\n",
    "            return_report[dataset] = {}\n",
    "            for report in self.cross_eval[dataset].keys():\n",
    "                return_report[dataset][report] = self.cross_eval[dataset][report][scoring]                \n",
    "        # 'report_dataframe': a dataframe where average values are selected\n",
    "        report_dataframe = pd.DataFrame(return_report).applymap(np.mean) \n",
    "        # Transpose the dataframe so that indices represent 'cross_eval_dataset' \n",
    "        report_dataframe = report_dataframe.transpose()\n",
    "        # Select the dataset with maximum score for training \n",
    "        max_train = report_dataframe.train.max()        \n",
    "        max_train_score_dataset = report_dataframe.train[report_dataframe.train==max_train].index\n",
    "        max_train_score_dataset = max_train_score_dataset[0]\n",
    "        # Select the dataset with maximum score for validation \n",
    "        max_valid = report_dataframe.cross_validate.max()        \n",
    "        max_valid_score_dataset = report_dataframe.cross_validate[report_dataframe.cross_validate==max_valid].index\n",
    "        max_valid_score_dataset = max_valid_score_dataset[0]\n",
    "        # Combine scores\n",
    "        max_score_dataset = {'train':max_train_score_dataset,\n",
    "                            'cross_validate':max_valid_score_dataset}\n",
    "        # Return 'return_report' dictionary, 'report_dataframe' dataframe and \n",
    "        # 'max_score_dataset' dataset string\n",
    "        return return_report, report_dataframe, max_score_dataset  \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit training data to a grid of models. \n",
    "        X: Training dataset \n",
    "        y: Training labels \n",
    "        \"\"\"\n",
    "        # Run if models are not fitted\n",
    "        if not self.fitted:\n",
    "            for model in self.models:\n",
    "                # Iterate through each model and fit training data\n",
    "                model.fit(X, y)\n",
    "            # Set 'fitted' to True     \n",
    "            self.fitted = True            \n",
    "            \n",
    "    def predict(self, X, y, train_test='test'):\n",
    "        \"\"\"\n",
    "        Predict values: Unlike predict functions for sklearn estimators, \n",
    "        this function takes y value as well, to report fitting metrics \n",
    "        X: Training/test dataset \n",
    "        y: Training/test labels \n",
    "        train_test: only 'train' and 'test' values need to be specified.\n",
    "        \"\"\"\n",
    "        # Dataframe to store prediction per 'train_test'\n",
    "        tr_ts = None\n",
    "        # Iterate through each model             \n",
    "        for model in self.models:\n",
    "            # Calculate predictions\n",
    "            preds = model.predict(X)\n",
    "            # Calculate the probabilities of predictions \n",
    "            prob_preds = model.predict_proba(X)\n",
    "            # Check if the model has 'decision_function'\n",
    "            if hasattr(model,'decision_function'):\n",
    "                score = model.decision_function(X)\n",
    "            else:\n",
    "                # Select scores for roc_curve calculation\n",
    "                score = prob_preds[:, 1]\n",
    "            # Find fpr and tpr values\n",
    "            fpr, tpr, threshold = roc_curve(y, score)\n",
    "            # Dict to store values \n",
    "            tmp = {}\n",
    "            # Populate 'tmp_df' with values\n",
    "            tmp['train_test'] = train_test\n",
    "            tmp['preds'] = [preds]\n",
    "            tmp['prob_preds'] = [prob_preds]\n",
    "            tmp['log_loss_score'] = log_loss(y, preds)\n",
    "            tmp['accuracy'] = accuracy_score(y, preds)\n",
    "            tmp['precision'] = precision_score(y, preds)\n",
    "            tmp['recall'] = recall_score(y, preds)\n",
    "            tmp['f1'] = f1_score(y, preds)\n",
    "            tmp['fpr'] = [fpr]\n",
    "            tmp['tpr'] = [tpr]\n",
    "            tmp['auc'] = auc(fpr, tpr)\n",
    "            tmp['roc_auc'] = roc_auc_score(y, preds)\n",
    "            # Create a temp dataframe with 'predictions' columns\n",
    "            tmp_df = pd.DataFrame(tmp)                \n",
    "            # Concatenate 'tmp_df' and 'tmp_df'\n",
    "            if not isinstance(tr_ts, pd.DataFrame): \n",
    "                tr_ts = tmp_df.copy()\n",
    "            else:\n",
    "                tr_ts = pd.concat([tr_ts,tmp_df])\n",
    "        # Reset indices \n",
    "        tr_ts.index = np.arange(len(self.models))\n",
    "        # Assign values to 'predictions'\n",
    "        if not isinstance(self.predictions, pd.DataFrame):\n",
    "            self.predictions = tr_ts.copy()\n",
    "        else:\n",
    "            self.predictions = pd.concat([self.predictions,tr_ts])\n",
    "    \n",
    "    def best_model(self, metrics=['accuracy'], valid_test='test'):\n",
    "        \"\"\"\n",
    "        This function returns the best model and model metrics \n",
    "        based on provided metrics from the test dataset.\n",
    "        metrics: A list of metrics\n",
    "        \"\"\"\n",
    "        # Select test cases only \n",
    "        test_metrics = self.predictions.loc[self.predictions.train_test==valid_test]\n",
    "        # Sort test_metrics by metrics in descending order          \n",
    "        test_metrics = test_metrics.sort_values(by=metrics, ascending=False)\n",
    "        # Reset indices  \n",
    "        test_metrics = test_metrics.reset_index()\n",
    "        # Best model index \n",
    "        idx = test_metrics.loc[0,:]['index']\n",
    "        # Return best model and best model metrics\n",
    "        if self.best_model_ is None: \n",
    "            self.best_model_ = self.models[idx]\n",
    "        return self.best_model_, test_metrics.loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_validate(estimator, X, y, cv=5):\n",
    "    \"\"\"\n",
    "    'custom_cross_validate' function that performs oversampling and cross \n",
    "    validate results.\n",
    "    X: Training dataset \n",
    "    y: Training labels\n",
    "    cv: The number of cross-validation folds \n",
    "    \"\"\"\n",
    "    # Create dictionaries to hold the scores from each fold\n",
    "    train_dict = {'log_loss_score':np.ndarray(cv), 'precision':np.ndarray(cv), \n",
    "                 'accuracy':np.ndarray(cv), 'recall':np.ndarray(cv), \n",
    "                  'f1':np.ndarray(cv),'fpr':[],\n",
    "                  'tpr':[], 'auc':np.ndarray(cv), 'roc_auc':np.ndarray(cv)\n",
    "                 }\n",
    "    valid_dict = {'log_loss_score':np.ndarray(cv), 'precision':np.ndarray(cv), \n",
    "                 'accuracy':np.ndarray(cv), 'recall':np.ndarray(cv), \n",
    "                  'f1':np.ndarray(cv),'fpr':[],\n",
    "                  'tpr':[], 'auc':np.ndarray(cv), 'roc_auc':np.ndarray(cv)\n",
    "                 }\n",
    "    \n",
    "    # Instantiate a splitter object and loop over its result\n",
    "    kfold = StratifiedKFold(n_splits=cv, shuffle=True)\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X, y)):\n",
    "        # Extract train and validation subsets using the provided indices\n",
    "        X_t, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_t, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "          \n",
    "        # Clone the provided model and fit it on the train subset\n",
    "        temp_model = clone(estimator)\n",
    "\n",
    "        # Fit the model \n",
    "        temp_model.fit(X_t, y_t)\n",
    "        \n",
    "        # Check if the mode has 'decision_function' attribute\n",
    "        if hasattr(temp_model, 'decision_function'):\n",
    "            train_score = temp_model.decision_function(X_t)\n",
    "            val_score = temp_model.decision_function(X_val)\n",
    "        else:        \n",
    "            # Calculate probablities \n",
    "            train_score = temp_model.predict_proba(X_t)[:,1]\n",
    "            val_score = temp_model.predict_proba(X_val)[:,1]\n",
    "                \n",
    "        # Find predictions \n",
    "        train_pred = temp_model.predict(X_t)\n",
    "        val_pred = temp_model.predict(X_val)\n",
    "        \n",
    "        # Evaluate the provided model on the train and validation subsets\n",
    "        # Log loss score \n",
    "        train_dict['log_loss_score'][fold] = log_loss(y_t, train_pred)\n",
    "        valid_dict['log_loss_score'][fold] = log_loss(y_val, val_pred)\n",
    "        # Accuracy score \n",
    "        train_dict['accuracy'][fold] = accuracy_score(y_t, train_pred)\n",
    "        valid_dict['accuracy'][fold] = accuracy_score(y_val, val_pred)\n",
    "        # Precision score \n",
    "        train_dict['precision'][fold] = precision_score(y_t, train_pred)\n",
    "        valid_dict['precision'][fold] = precision_score(y_val, val_pred)\n",
    "        # Recall score\n",
    "        train_dict['recall'][fold] = recall_score(y_t, train_pred)\n",
    "        valid_dict['recall'][fold] = recall_score(y_val, val_pred)\n",
    "        # F1 score \n",
    "        train_dict['f1'][fold] = f1_score(y_t, train_pred)\n",
    "        valid_dict['f1'][fold] = f1_score(y_val, val_pred)\n",
    "        # FPR and TPR \n",
    "        train_fpr, train_tpr, threshold = roc_curve(y_t, train_score)\n",
    "        valid_fpr, valid_tpr, threshold = roc_curve(y_val, val_score)\n",
    "        train_dict['fpr'].append(train_fpr)\n",
    "        train_dict['tpr'].append(train_tpr)\n",
    "        valid_dict['fpr'].append(valid_fpr)\n",
    "        valid_dict['tpr'].append(valid_tpr)\n",
    "        # AUC\n",
    "        train_dict['auc'][fold] = auc(train_fpr, train_tpr)\n",
    "        valid_dict['auc'][fold] = auc(valid_fpr, valid_tpr)\n",
    "        # ROC_AUC \n",
    "        train_dict['roc_auc'][fold] = roc_auc_score(y_t, train_pred)\n",
    "        valid_dict['roc_auc'][fold] = roc_auc_score(y_val, val_pred)\n",
    "        \n",
    "    # Return training and validation results\n",
    "    return train_dict, valid_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function helps in visualizing the log losses, combined ROC curves of training and validation datasets, and performance metrics of training and validation datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_metrics(model_grid, train_val='train'):\n",
    "    \"\"\"\n",
    "    This function plots metrics on different datasets\n",
    "    model_grid: Custom_GridSearchCV object\n",
    "    Run this code after fitting. \n",
    "    \"\"\"    \n",
    "    # Convert cross_eval from Custom_GrisSearchCV into dataframe\n",
    "    # Table is transposed to set dataset as columns\n",
    "    tmp = pd.DataFrame(model_grid.cross_eval).transpose()\n",
    "    tmp = pd.DataFrame(tmp[train_val].to_dict())\n",
    "    # Initialize metrics dataframe \n",
    "    metrics = pd.DataFrame(columns=list(tmp.columns)+['metric'])\n",
    "    # Iterate through each metric in 'tmp' and assign to metrics dataframe\n",
    "    for idx in tmp.index:\n",
    "        # Create an empty dataframe \n",
    "        metric = pd.DataFrame(tmp.loc[idx,:].to_dict())\n",
    "        # Update type of metric \n",
    "        metric['metric'] = idx\n",
    "        # Append results\n",
    "        metrics = pd.concat([metrics, metric])\n",
    "    # Reset metrics\n",
    "    metrics = metrics.reset_index()\n",
    "    # Rename 'index' column to 'fold'\n",
    "    metrics.rename(columns={'index':'fold'}, inplace=True)\n",
    "    # Initialiaze squeezed metrics dataframe\n",
    "    squeezed_metrics = pd.DataFrame(columns=['fold','metric','dataset',\n",
    "                                             'value','train_val'])\n",
    "    # Iterate through each column and populate 'squeezed_metrics'\n",
    "    for col in model_grid.cross_eval.keys():\n",
    "        # Create empty dataframe \n",
    "        sq_met = pd.DataFrame(columns=squeezed_metrics.columns)\n",
    "        # Populate 'sq_met'\n",
    "        sq_met.fold = metrics.fold\n",
    "        sq_met.metric = metrics.metric\n",
    "        sq_met.dataset = col\n",
    "        sq_met.value = metrics[col]\n",
    "        sq_met.train_val = train_val\n",
    "        # Append 'sq_met' to 'squeezed_metrics'\n",
    "        squeezed_metrics = pd.concat([squeezed_metrics, sq_met], \n",
    "                                     ignore_index=True)\n",
    "    # Set log-loss to a variable and remove the column from 'squeezed_metrics'\n",
    "    log_loss_vals =  squeezed_metrics.loc[squeezed_metrics.metric =='log_loss_score']\n",
    "    squeezed_metrics.drop(log_loss_vals.index, inplace=True)\n",
    "    # Get fpr and tpr from 'squeezed_metrics'\n",
    "    fpr = squeezed_metrics.loc[squeezed_metrics.metric=='fpr']\n",
    "    tpr = squeezed_metrics.loc[squeezed_metrics.metric=='tpr']\n",
    "    # Drop 'fpr' and 'tpr' from 'squeezed_metrics'\n",
    "    squeezed_metrics.drop(fpr.index, inplace=True)\n",
    "    squeezed_metrics.drop(tpr.index, inplace=True)\n",
    "    # Find the longest fpr/tpr\n",
    "    roc_max_len = fpr.value.apply(lambda x: len(x)).max()\n",
    "    # Reset indices for 'fpr' and 'tpr'\n",
    "    fpr = fpr.reset_index()\n",
    "    tpr = tpr.reset_index()\n",
    "    # Initialize 'fpr_mat' and 'tpr_mat' \n",
    "    fpr_mat = np.zeros((len(fpr), roc_max_len))\n",
    "    tpr_mat = np.zeros((len(tpr), roc_max_len))\n",
    "    # Iteratre through each fpr and tpr, and interpolate values\n",
    "    for i in range(len(fpr)):\n",
    "        # Create a uniformly spaced 'fpr' values\n",
    "        xvals = np.linspace(0, 1, roc_max_len)\n",
    "        # Interpolate y values \n",
    "        yinterp = np.interp(xvals, fpr.loc[i,'value'], tpr.loc[i,'value'])\n",
    "        # Update fpr and tpr matrix \n",
    "        fpr_mat[i,:] = xvals\n",
    "        tpr_mat[i,:] = yinterp\n",
    "    # Create roc_vals dictionary \n",
    "    roc_vals = {}\n",
    "    # Instead of taking the entire matrices, the mean and std values are \n",
    "    # selected for 'fpr' and 'tpr'\n",
    "    roc_vals['fpr_mean'] = fpr_mat.mean(axis=0)\n",
    "    roc_vals['tpr_mean'] = tpr_mat.mean(axis=0)\n",
    "    roc_vals['fpr_std'] = fpr_mat.std(axis=0)\n",
    "    roc_vals['tpr_std'] = tpr_mat.std(axis=0)\n",
    "    # Return squeezed metrics, log loss and roc \n",
    "    return squeezed_metrics, log_loss_vals, roc_vals\n",
    "\n",
    "\n",
    "def plot_metrics(model_grid):\n",
    "    \"\"\"\n",
    "    This function plots metrics on different datasets\n",
    "    model_grid: Custom_GridSearchCV object\n",
    "    Run this code after fitting. \n",
    "    \"\"\"    \n",
    "    # Get parameters for training \n",
    "    tr_metrics, tr_log_loss, tr_roc_vals = prepare_metrics(model_grid, \n",
    "                                                           'train')\n",
    "    # Get parameters for validation\n",
    "    vl_metrics, vl_log_loss, vl_roc_vals = prepare_metrics(model_grid, \n",
    "                                                           'cross_validate')\n",
    "    # Combine log losses for training and validation \n",
    "    log_loss_combined = pd.concat([tr_log_loss,vl_log_loss])\n",
    "    # Create figure to plot log loss and ROC curve \n",
    "    fig, axes = plt.subplots(1 , 2, figsize=(15,6))\n",
    "    # Log loss for training and validation \n",
    "    g1 = sns.boxplot(x=\"dataset\", y=\"value\", hue=\"train_val\",\n",
    "                     data=log_loss_combined, ax=axes[0])\n",
    "    # Format labels and title \n",
    "    g1.set_xlabel('')\n",
    "    g1.set_ylabel('Log Loss',fontsize=13)\n",
    "    g1.set_title('Log Loss vs Dataset',fontsize=15)\n",
    "    g1.legend(title='Fold')\n",
    "    \n",
    "    # Plot mean ROC curve for training fold\n",
    "    g2 = sns.lineplot(x=tr_roc_vals['fpr_mean'], y=tr_roc_vals['tpr_mean'], \n",
    "                  label='train', ax=axes[1], color='tab:blue')\n",
    "    # Plot the standard deviation for training ROC \n",
    "    plt.fill_between(tr_roc_vals['fpr_mean'], \n",
    "                     tr_roc_vals['tpr_mean'] - tr_roc_vals['tpr_std'],\n",
    "                     tr_roc_vals['tpr_mean'] + tr_roc_vals['tpr_std'],\n",
    "                     color='tab:blue', alpha=0.2)\n",
    "    # Plot mean ROC curve for validation fold\n",
    "    sns.lineplot(x=vl_roc_vals['fpr_mean'], y=vl_roc_vals['tpr_mean'], \n",
    "                  label='cross_validate', ax=axes[1], color='tab:orange')\n",
    "    # Plot the standard deviation for validation ROC\n",
    "    plt.fill_between(vl_roc_vals['fpr_mean'], \n",
    "                     vl_roc_vals['tpr_mean'] - vl_roc_vals['tpr_std'],\n",
    "                     vl_roc_vals['tpr_mean'] + vl_roc_vals['tpr_std'],\n",
    "                     color='tab:orange', alpha=0.2)\n",
    "    \n",
    "    # Format labels and title \n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    g2.set_xlabel('False Positve Rate', fontsize=13)\n",
    "    g2.legend(title='Fold')\n",
    "    g2.set_ylabel('True Positve Rate', fontsize=13)\n",
    "    g2.set_title('ROC Curve',fontsize=15)\n",
    "    \n",
    "    # Plot metrics for training fold\n",
    "    fig, axes = plt.subplots(2 , 1, figsize=(15,12))\n",
    "    g3 = sns.boxplot(x=\"dataset\", y=\"value\", hue=\"metric\",\n",
    "                     data=tr_metrics, ax=axes[0])\n",
    "    # Format labels and title\n",
    "    g3.set_xlabel('')\n",
    "    g3.set_ylabel('Score', fontsize=13)\n",
    "    g3.set_title('Training Scores vs Dataset',fontsize=15)\n",
    "    g3.legend(title='Metric')\n",
    "    \n",
    "    # Plot metrics for validation fold\n",
    "    g4 = sns.boxplot(x=\"dataset\", y=\"value\", hue=\"metric\",\n",
    "                     data=vl_metrics, ax=axes[1])\n",
    "    # Format labels and title\n",
    "    g4.set_xlabel('')\n",
    "    g4.set_ylabel('Score',fontsize=13)\n",
    "    g4.set_title('Cross Validation Scores vs Dataset',fontsize=15)\n",
    "    g4.legend(title='Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function also does similar operations for training and test datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_predictions(model_grid, train_test='test'):\n",
    "    \"\"\"\n",
    "    This function plots metrics on train/test predictions \n",
    "    model_grid: Custom_GridSearchCV object\n",
    "    Run this code after fitting. \n",
    "    \"\"\"    \n",
    "    # Convert prediction from Custom_GrisSearchCV into dataframe    \n",
    "    # Select train or test\n",
    "    tmp = model_grid.predictions.loc[model_grid.predictions.train_test==train_test]\n",
    "    # Initialize squeezed predictions     \n",
    "    squeezed_preds = pd.DataFrame(columns=['metric','value','train_test'])\n",
    "    # Find metrics from 'cross_eval' \n",
    "    columns = model_grid.cross_eval['TfIdf']['train'].keys()\n",
    "    # Iterate through 'predictions' columns \n",
    "    for col in columns:\n",
    "        # Initialize a dummy dataframe for each column\n",
    "        sq_preds = pd.DataFrame(columns=squeezed_preds.columns)\n",
    "        # Assign values \n",
    "        sq_preds.value = tmp[col]\n",
    "        sq_preds.train_test = tmp['train_test']\n",
    "        sq_preds.metric = col\n",
    "        # Append values to 'squeezed_preds'\n",
    "        squeezed_preds = pd.concat([squeezed_preds,sq_preds])\n",
    "    # Reset index\n",
    "    squeezed_preds = squeezed_preds.reset_index()\n",
    "    # Get log loss from 'squeezed_preds'    \n",
    "    log_loss_vals = squeezed_preds.loc[squeezed_preds.metric=='log_loss_score']\n",
    "    squeezed_preds.drop(log_loss_vals.index, inplace=True)\n",
    "    # Get fpr and tpr from 'squeezed_preds'\n",
    "    fpr = squeezed_preds.loc[squeezed_preds.metric=='fpr']\n",
    "    tpr = squeezed_preds.loc[squeezed_preds.metric=='tpr']\n",
    "    # Drop 'fpr' and 'tpr' from 'squeezed_preds'\n",
    "    squeezed_preds.drop(fpr.index, inplace=True)\n",
    "    squeezed_preds.drop(tpr.index, inplace=True)\n",
    "    # Find the longest fpr/tpr\n",
    "    roc_max_len = fpr.value.apply(lambda x: len(x)).max()\n",
    "    # Reset indices for 'fpr' and 'tpr'\n",
    "    fpr = fpr.reset_index()\n",
    "    tpr = tpr.reset_index()\n",
    "    # Initialize 'fpr_mat' and 'tpr_mat' \n",
    "    fpr_mat = np.zeros((len(fpr), roc_max_len))\n",
    "    tpr_mat = np.zeros((len(tpr), roc_max_len))\n",
    "    # Iteratre through each fpr and tpr, and interpolate values\n",
    "    for i in range(len(fpr)):\n",
    "        # Create a uniformly spaced 'fpr' values\n",
    "        xvals = np.linspace(0, 1, roc_max_len)\n",
    "        # Interpolate y values \n",
    "        yinterp = np.interp(xvals, fpr.loc[i,'value'], tpr.loc[i,'value'])\n",
    "        # Update fpr and tpr matrix \n",
    "        fpr_mat[i,:] = xvals\n",
    "        tpr_mat[i,:] = yinterp\n",
    "    # Create roc_vals dictionary \n",
    "    roc_vals = {}\n",
    "    # Instead of taking the entire matrices, the mean and std values are \n",
    "    # selected for 'fpr' and 'tpr'\n",
    "    roc_vals['fpr_mean'] = fpr_mat.mean(axis=0)\n",
    "    roc_vals['tpr_mean'] = tpr_mat.mean(axis=0)\n",
    "    roc_vals['fpr_std'] = fpr_mat.std(axis=0)\n",
    "    roc_vals['tpr_std'] = tpr_mat.std(axis=0)\n",
    "    # Return squeezed metrics, log loss and roc \n",
    "    return squeezed_preds, log_loss_vals, roc_vals\n",
    "\n",
    "def plot_predictions(model_grid, valid_test='test'):\n",
    "    \"\"\"\n",
    "    This function plots predictions on different datasets\n",
    "    model_grid: Custom_GridSearchCV object\n",
    "    Run this code after fitting. \n",
    "    \"\"\"    \n",
    "    # Get parameters for training \n",
    "    tr_preds, tr_log_loss, tr_roc_vals = prepare_predictions(model_grid, \n",
    "                                                           'train')\n",
    "    # Get parameters for validation\n",
    "    ts_preds, ts_log_loss, ts_roc_vals = prepare_predictions(model_grid, \n",
    "                                                           valid_test)\n",
    "    # Combine log losses for training and validation \n",
    "    log_loss_combined = pd.concat([tr_log_loss,ts_log_loss])\n",
    "    # Create figure to plot log loss and ROC curve \n",
    "    fig, axes = plt.subplots(1 , 2, figsize=(15,6))\n",
    "    # Log loss for training and validation \n",
    "    g1 = sns.boxplot(x=\"metric\", y=\"value\", hue=\"train_test\",\n",
    "                     data=log_loss_combined, ax=axes[0])\n",
    "    # Format labels and title \n",
    "    g1.set_xlabel('')\n",
    "    g1.set_ylabel('Log Loss',fontsize=13)\n",
    "    g1.set_title('Log Loss vs Dataset',fontsize=15)\n",
    "    g1.legend(title='Dataset')\n",
    "    \n",
    "    # Plot mean ROC curve for training fold\n",
    "    g2 = sns.lineplot(x=tr_roc_vals['fpr_mean'], y=tr_roc_vals['tpr_mean'], \n",
    "                  label='train', ax=axes[1], color='tab:blue')\n",
    "    # Plot the standard deviation for training ROC \n",
    "    plt.fill_between(tr_roc_vals['fpr_mean'], \n",
    "                     tr_roc_vals['tpr_mean'] - tr_roc_vals['tpr_std'],\n",
    "                     tr_roc_vals['tpr_mean'] + tr_roc_vals['tpr_std'],\n",
    "                     color='tab:blue', alpha=0.2)\n",
    "    # Plot mean ROC curve for validation fold\n",
    "    sns.lineplot(x=ts_roc_vals['fpr_mean'], y=ts_roc_vals['tpr_mean'], \n",
    "                  label=valid_test, ax=axes[1], color='tab:orange')\n",
    "    # Plot the standard deviation for validation ROC\n",
    "    plt.fill_between(ts_roc_vals['fpr_mean'], \n",
    "                     ts_roc_vals['tpr_mean'] - ts_roc_vals['tpr_std'],\n",
    "                     ts_roc_vals['tpr_mean'] + ts_roc_vals['tpr_std'],\n",
    "                     color='tab:orange', alpha=0.2)\n",
    "    \n",
    "    # Format labels and title \n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    g2.set_xlabel('False Positve Rate', fontsize=13)\n",
    "    g2.legend(title='Dataset')\n",
    "    g2.set_ylabel('True Positve Rate', fontsize=13)\n",
    "    g2.set_title('ROC Curve',fontsize=15)\n",
    "\n",
    "    # Plot metrics for training data\n",
    "    preds = pd.concat([tr_preds,ts_preds])\n",
    "    fig, ax = plt.subplots(figsize=(15,6))\n",
    "    g3 = sns.boxplot(x=\"train_test\", y=\"value\", hue=\"metric\",\n",
    "                     data=preds, ax=ax)\n",
    "    # Format labels and title\n",
    "    g3.set_xlabel('')\n",
    "    g3.set_ylabel('Score', fontsize=13)\n",
    "    g3.set_title('Scores vs Training and '+valid_test.title()+' Datasets',fontsize=15)\n",
    "    g3.legend(title='Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, normalize=None):\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize=normalize)\n",
    "    sns.heatmap(cm, annot=True, cmap='viridis', linecolor='black', \n",
    "                linewidth=1, ax=ax)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlim(2,0)\n",
    "    plt.ylim(0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the models take a long time. So, the models are saved as `dill` files that can be read from file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performing models and their predictions will be stored in these variables.\n",
    "\n",
    "<b><font color='red'>CAUTION: running the entire notebook takes at least 8 hours.</font></b> \n",
    "\n",
    "The pretrained model can be found in [this link](https://drive.google.com/file/d/1-35hJfJi4Z8ahXzGrHPJfPpMSibErAHx/view?usp=drivesdk). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best models list \n",
    "best_models = []\n",
    "\n",
    "# Metrics for best models \n",
    "best_models_metrics = None \n",
    "\n",
    "# Define metrics by importance\n",
    "metrics = ['accuracy','auc','recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model used is logistic regression. Regularization factor, fit intercept, and L1 or L2 penalty were considered for grid search. `lbfgs` solver does not allow for L1 penalty. So, `liblinear` solver used instead. The downside is that ` liblinear` does not allow for parallelized jobs, which is why ‘n_jobs’ is missing as an input parameter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the variable exists\n",
    "if not exists('nb_gs.pickle'):    \n",
    "\n",
    "    # Define parameters ranges \n",
    "    params = {'alpha':['0','1'],\n",
    "              'fit_prior':['False','True']}\n",
    "\n",
    "    # Create a Custom_GridSearchCV instance\n",
    "    nb_gs = Custom_GridSearchCV('MultinomialNB', param_grid=params)\n",
    "else:\n",
    "    with open('nb_gs.pickle', 'rb') as f:\n",
    "        nb_gs = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation with accuracy as the primary scoring\n",
    "rprt, rp_df, _ = nb_gs.cross_validate(X_train_vec[:2], y_train, \n",
    "                                      vectorization=vec_labels[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In orders to choose the best dataset to fit with the model, let's aggregate the metrics. Sorting the average accuracy, recall and AUC metrics yields: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TfIdf_train</th>\n",
       "      <td>0.793827</td>\n",
       "      <td>0.795987</td>\n",
       "      <td>0.799663</td>\n",
       "      <td>0.796734</td>\n",
       "      <td>0.881023</td>\n",
       "      <td>0.795987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfIdf_cross_validate</th>\n",
       "      <td>0.793735</td>\n",
       "      <td>0.795919</td>\n",
       "      <td>0.799639</td>\n",
       "      <td>0.796675</td>\n",
       "      <td>0.880983</td>\n",
       "      <td>0.795919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count_train</th>\n",
       "      <td>0.792897</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.801025</td>\n",
       "      <td>0.79694</td>\n",
       "      <td>0.875053</td>\n",
       "      <td>0.7959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count_cross_validate</th>\n",
       "      <td>0.792864</td>\n",
       "      <td>0.795862</td>\n",
       "      <td>0.800981</td>\n",
       "      <td>0.796901</td>\n",
       "      <td>0.875016</td>\n",
       "      <td>0.795862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     precision  accuracy    recall        f1       auc  \\\n",
       "TfIdf_train           0.793827  0.795987  0.799663  0.796734  0.881023   \n",
       "TfIdf_cross_validate  0.793735  0.795919  0.799639  0.796675  0.880983   \n",
       "Count_train           0.792897    0.7959  0.801025   0.79694  0.875053   \n",
       "Count_cross_validate  0.792864  0.795862  0.800981  0.796901  0.875016   \n",
       "\n",
       "                       roc_auc  \n",
       "TfIdf_train           0.795987  \n",
       "TfIdf_cross_validate  0.795919  \n",
       "Count_train             0.7959  \n",
       "Count_cross_validate  0.795862  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find training and validation metrics\n",
    "nb_gs_metrics_train,_,_ = prepare_metrics(nb_gs, train_val='train')\n",
    "nb_gs_metrics_valid,_,_ = prepare_metrics(nb_gs, train_val='cross_validate')\n",
    "\n",
    "# Combine metrics \n",
    "nb_gs_metrics = pd.concat([nb_gs_metrics_train,nb_gs_metrics_valid])\n",
    "\n",
    "# Rename dataset as 'dataset_train/validate'\n",
    "nb_gs_metrics.dataset = nb_gs_metrics.dataset+'_'+nb_gs_metrics.train_val\n",
    "\n",
    "# Create a placeholder dataframe to store the average values\n",
    "nb_gs_metrics_mean = pd.DataFrame(columns=nb_gs_metrics.metric.unique(),\n",
    "                                  index=nb_gs_metrics.dataset.unique())\n",
    "\n",
    "# Iterate through each row and column, aggregate values and take the mean\n",
    "for col in nb_gs_metrics_mean.columns:\n",
    "    for idx in nb_gs_metrics_mean.index:\n",
    "        avg = nb_gs_metrics.loc[(nb_gs_metrics.metric==col) & (nb_gs_metrics.dataset==idx),'value']\n",
    "        nb_gs_metrics_mean.loc[idx,col] = avg.mean()\n",
    "\n",
    "# Sort average metrics by recall, AUC and accuracy        \n",
    "nb_gs_metrics_mean.sort_values(by=metrics,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance metrics of the model are shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the metrics for training and validation datasets\n",
    "plot_metrics(nb_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although `rand` did have the highest accuracy, `class_weight` had consistent performance with the training and validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit grid search models with the best training dataset\n",
    "# Specifying embedding to have better accuracy values\n",
    "nb_gs.fit(X_train_vec[0], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's produce predictions based on the model grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_test</th>\n",
       "      <th>preds</th>\n",
       "      <th>prob_preds</th>\n",
       "      <th>log_loss_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>auc</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validate</td>\n",
       "      <td>[1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>[[0.3902222283229388, 0.6097777716770622], [0....</td>\n",
       "      <td>8.928094</td>\n",
       "      <td>0.741508</td>\n",
       "      <td>0.736084</td>\n",
       "      <td>0.752996</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.8518518518518519e-06, 1.8518...</td>\n",
       "      <td>[0.0, 1.8518518518518519e-06, 0.00014814814814...</td>\n",
       "      <td>0.821527</td>\n",
       "      <td>0.741508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validate</td>\n",
       "      <td>[1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>[[0.3902222283229388, 0.60977777167706], [0.72...</td>\n",
       "      <td>8.928094</td>\n",
       "      <td>0.741508</td>\n",
       "      <td>0.736084</td>\n",
       "      <td>0.752996</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.8518518518518519e-06, 1.8518...</td>\n",
       "      <td>[0.0, 1.8518518518518519e-06, 0.00014814814814...</td>\n",
       "      <td>0.821527</td>\n",
       "      <td>0.741508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>validate</td>\n",
       "      <td>[1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>[[0.3902264776423026, 0.6097735223576966], [0....</td>\n",
       "      <td>8.928094</td>\n",
       "      <td>0.741508</td>\n",
       "      <td>0.736081</td>\n",
       "      <td>0.753004</td>\n",
       "      <td>0.744446</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.8518518518518519e-06, 1.8518...</td>\n",
       "      <td>[0.0, 1.8518518518518519e-06, 0.00014814814814...</td>\n",
       "      <td>0.821528</td>\n",
       "      <td>0.741508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>validate</td>\n",
       "      <td>[1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>[[0.3902264776423026, 0.6097735223576966], [0....</td>\n",
       "      <td>8.928094</td>\n",
       "      <td>0.741508</td>\n",
       "      <td>0.736081</td>\n",
       "      <td>0.753004</td>\n",
       "      <td>0.744446</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.8518518518518519e-06, 1.8518...</td>\n",
       "      <td>[0.0, 1.8518518518518519e-06, 0.00014814814814...</td>\n",
       "      <td>0.821528</td>\n",
       "      <td>0.741508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>[[0.6285026028322631, 0.37149739716773683], [0...</td>\n",
       "      <td>16.562082</td>\n",
       "      <td>0.520480</td>\n",
       "      <td>0.566003</td>\n",
       "      <td>0.175625</td>\n",
       "      <td>0.268071</td>\n",
       "      <td>[0.0, 7.936507936507937e-07, 7.936507936507937...</td>\n",
       "      <td>[0.0, 0.0, 1.5873015873015873e-06, 1.587301587...</td>\n",
       "      <td>0.540398</td>\n",
       "      <td>0.520480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_test                                              preds  \\\n",
       "0   validate  [1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, ...   \n",
       "1   validate  [1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, ...   \n",
       "2   validate  [1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, ...   \n",
       "3   validate  [1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, ...   \n",
       "0      train  [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, ...   \n",
       "\n",
       "                                          prob_preds  log_loss_score  \\\n",
       "0  [[0.3902222283229388, 0.6097777716770622], [0....        8.928094   \n",
       "1  [[0.3902222283229388, 0.60977777167706], [0.72...        8.928094   \n",
       "2  [[0.3902264776423026, 0.6097735223576966], [0....        8.928094   \n",
       "3  [[0.3902264776423026, 0.6097735223576966], [0....        8.928094   \n",
       "0  [[0.6285026028322631, 0.37149739716773683], [0...       16.562082   \n",
       "\n",
       "   accuracy  precision    recall        f1  \\\n",
       "0  0.741508   0.736084  0.752996  0.744444   \n",
       "1  0.741508   0.736084  0.752996  0.744444   \n",
       "2  0.741508   0.736081  0.753004  0.744446   \n",
       "3  0.741508   0.736081  0.753004  0.744446   \n",
       "0  0.520480   0.566003  0.175625  0.268071   \n",
       "\n",
       "                                                 fpr  \\\n",
       "0  [0.0, 0.0, 0.0, 1.8518518518518519e-06, 1.8518...   \n",
       "1  [0.0, 0.0, 0.0, 1.8518518518518519e-06, 1.8518...   \n",
       "2  [0.0, 0.0, 0.0, 1.8518518518518519e-06, 1.8518...   \n",
       "3  [0.0, 0.0, 0.0, 1.8518518518518519e-06, 1.8518...   \n",
       "0  [0.0, 7.936507936507937e-07, 7.936507936507937...   \n",
       "\n",
       "                                                 tpr       auc   roc_auc  \n",
       "0  [0.0, 1.8518518518518519e-06, 0.00014814814814...  0.821527  0.741508  \n",
       "1  [0.0, 1.8518518518518519e-06, 0.00014814814814...  0.821527  0.741508  \n",
       "2  [0.0, 1.8518518518518519e-06, 0.00014814814814...  0.821528  0.741508  \n",
       "3  [0.0, 1.8518518518518519e-06, 0.00014814814814...  0.821528  0.741508  \n",
       "0  [0.0, 0.0, 1.5873015873015873e-06, 1.587301587...  0.540398  0.520480  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict test and training datasets \n",
    "# Also get the metrics of fit\n",
    "# Check if the models have not been predicted yet \n",
    "if not isinstance(nb_gs.predictions, pd.DataFrame):\n",
    "    prep = Preprocess(transformer='tfidf',max_df=0.979,min_df=0.0201)\n",
    "    nb_gs.predict(prep.transform(X_valid), y_valid, train_test='validate')\n",
    "    nb_gs.predict(X_train_vec[-1], y_train, train_test='train')\n",
    "nb_gs.predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting metrics over the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-b0d698900df4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plot metrics for predicted values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_gs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'validate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-0d69a3e70145>\u001b[0m in \u001b[0;36mplot_predictions\u001b[1;34m(model_grid, valid_test)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;31m# Plot mean ROC curve for training fold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     g2 = sns.lineplot(x=tr_roc_vals['fpr_mean'], y=tr_roc_vals['tpr_mean'], \n\u001b[0m\u001b[0;32m     90\u001b[0m                   label='train', ax=axes[1], color='tab:blue')\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Plot the standard deviation for training ROC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36mlineplot\u001b[1;34m(x, y, hue, size, style, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, units, estimator, ci, n_boot, seed, sort, err_style, err_kws, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_attach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, ax, kws)\u001b[0m\n\u001b[0;32m    490\u001b[0m                     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"estimator must be None when specifying units\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m                 \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ci\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m                 \u001b[0my_ci\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, vals, grouper, units)\u001b[0m\n\u001b[0;32m    412\u001b[0m                                columns=[\"low\", \"high\"]).stack()\n\u001b[0;32m    413\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[0mcis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbootstrapped_cis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;31m# Unpack the CIs into \"wide\" format for plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m     )\n\u001b[0;32m    225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     @doc(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode.chained_assignment\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m                 \u001b[1;31m# gh-20949\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[1;34m(self, f, data)\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \"\"\"\n\u001b[1;32m--> 892\u001b[1;33m         \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[0mresult_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36m_is_indexed_like\u001b[1;34m(obj, axes)\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mequals\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   4253\u001b[0m         \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4254\u001b[0m         \"\"\"\n\u001b[1;32m-> 4255\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mis_\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mis_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m         \"\"\"\n\u001b[0;32m    522\u001b[0m         \u001b[0mMore\u001b[0m \u001b[0mflexible\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaster\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mworks\u001b[0m \u001b[0mthrough\u001b[0m \u001b[0mviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot metrics for predicted values\n",
    "plot_predictions(nb_gs, valid_test='validate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, recall and AUC are used to determine the best model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model and model metrics based on given metrics \n",
    "best_nb_model, best_nb_model_metrics = nb_gs.best_model(metrics=metrics, \n",
    "                                                        valid_test='validate')\n",
    "\n",
    "# Store best model \n",
    "# best_models.append(best_logreg_model)\n",
    "\n",
    "# Store best model metrics \n",
    "# best_models_metrics = pd.DataFrame(best_logreg_model_metrics).transpose()\n",
    "\n",
    "# Display best model parameters \n",
    "best_nb_model.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the metrics for the best performing model and plotting the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best logreg model metrics\n",
    "best_nb_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "plot_confusion_matrix(y_valid, best_nb_model_metrics.preds, \n",
    "                      normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists('nb_gs.pickle'):\n",
    "    with open('nb_gs.pickle', 'wb') as f:    \n",
    "        pickle.dump(nb_gs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the model did well for the true positive prediction at the cost of lower accuracy. This is acceptable given the class imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model used is logistic regression. Regularization factor, fit intercept, and L1 or L2 penalty were considered for grid search. `lbfgs` solver does not allow for L1 penalty. So, `liblinear` solver used instead. The downside is that ` liblinear` does not allow for parallelized jobs, which is why ‘n_jobs’ is missing as an input parameter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the variable exists\n",
    "if not exists('logreg_gs.pickle'):    \n",
    "    # Define regularization range \n",
    "    C = np.linspace(0.1, 1, 2)\n",
    "\n",
    "    # Define parameters ranges \n",
    "    params = {'C':[str(s) for s in C],\n",
    "              'fit_intercept':['False','True'],\n",
    "              'max_iter':['1e3'],\n",
    "              'penalty':[\"'l1'\",\"'l2'\"],\n",
    "              'solver':[\"'liblinear'\"]}\n",
    "\n",
    "    # Create a Custom_GridSearchCV instance\n",
    "    logreg_gs = Custom_GridSearchCV('LogisticRegression', param_grid=params)\n",
    "else:\n",
    "    with open('logreg_gs.pickle', 'rb') as f:\n",
    "        logreg_gs = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation with accuracy as the primary scoring\n",
    "rprt, rp_df, _ = logreg_gs.cross_validate(X_train_vec, y_train, \n",
    "                                          vectorization=vec_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In orders to choose the best dataset to fit with the model, let's aggregate the metrics. Sorting the average accuracy, recall and AUC metrics yields: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find training and validation metrics\n",
    "logreg_gs_metrics_train,_,_ = prepare_metrics(logreg_gs, train_val='train')\n",
    "logreg_gs_metrics_valid,_,_ = prepare_metrics(logreg_gs, train_val='cross_validate')\n",
    "\n",
    "# Combine metrics \n",
    "logreg_gs_metrics = pd.concat([logreg_gs_metrics_train,logreg_gs_metrics_valid])\n",
    "\n",
    "# Rename dataset as 'dataset_train/validate'\n",
    "logreg_gs_metrics.dataset = logreg_gs_metrics.dataset+'_'+logreg_gs_metrics.train_val\n",
    "\n",
    "# Create a placeholder dataframe to store the average values\n",
    "logreg_gs_metrics_mean = pd.DataFrame(columns=logreg_gs_metrics.metric.unique(),\n",
    "                                  index=logreg_gs_metrics.dataset.unique())\n",
    "\n",
    "# Iterate through each row and column, aggregate values and take the mean\n",
    "for col in logreg_gs_metrics_mean.columns:\n",
    "    for idx in logreg_gs_metrics_mean.index:\n",
    "        avg = logreg_gs_metrics.loc[(logreg_gs_metrics.metric==col) & (logreg_gs_metrics.dataset==idx),'value']\n",
    "        logreg_gs_metrics_mean.loc[idx,col] = avg.mean()\n",
    "\n",
    "# Sort average metrics by recall, AUC and accuracy        \n",
    "logreg_gs_metrics_mean.sort_values(by=metrics,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance metrics of the model are shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the metrics for training and validation datasets\n",
    "plot_metrics(logreg_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although `rand` did have the highest accuracy, `class_weight` had consistent performance with the training and validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit grid search models with the best training dataset\n",
    "# Specifying embedding to have better accuracy values\n",
    "logreg_gs.fit(X_train_vec[-1], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's produce predictions based on the model grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test and training datasets \n",
    "# Also get the metrics of fit\n",
    "# Check if the models have not been predicted yet \n",
    "if not isinstance(logreg_gs.predictions, pd.DataFrame):\n",
    "    prep = Preprocess(transformer='embed')\n",
    "    logreg_gs.predict(prep.transform(X_valid), y_valid, train_test='validate')\n",
    "    logreg_gs.predict(X_train_vec[-1], y_train, train_test='train')\n",
    "logreg_gs.predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting metrics over the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics for predicted values\n",
    "plot_predictions(logreg_gs, valid_test='validate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, recall and AUC are used to determine the best model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model and model metrics based on given metrics \n",
    "best_logreg_model, best_logreg_model_metrics = logreg_gs.best_model(metrics=metrics, \n",
    "                                                                    valid_test='validate')\n",
    "\n",
    "# Store best model \n",
    "# best_models.append(best_logreg_model)\n",
    "\n",
    "# Store best model metrics \n",
    "# best_models_metrics = pd.DataFrame(best_logreg_model_metrics).transpose()\n",
    "\n",
    "# Display best model parameters \n",
    "best_logreg_model.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the metrics for the best performing model and plotting the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best logreg model metrics\n",
    "best_logreg_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "plot_confusion_matrix(y_valid, best_logreg_model_metrics.preds, \n",
    "                      normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists('logreg_gs.pickle'):\n",
    "    with open('logreg_gs.pickle', 'wb') as f:    \n",
    "        pickle.dump(logreg_gs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the model did well for the true positive prediction at the cost of lower accuracy. This is acceptable given the class imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us apply the same method using random forest instead. Fewer parameters are used in lieu of memory requirements is larger parameter space were to be used.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the variable exists\n",
    "if not exists('rf_gs.pickle'):\n",
    "    # Define n_estimators range\n",
    "    n_estimators = np.arange(30, 100, 30)\n",
    "\n",
    "    # Define min_sample_split range \n",
    "    min_samples_split = np.linspace(0.1, 1, 2, endpoint=True)\n",
    "\n",
    "    # Define parameters ranges \n",
    "    params = {'max_depth':['None']+[str(s) for s in np.arange(1, 51, 20)],\n",
    "              'min_samples_split':['2']+[str(s) for s in min_samples_split],\n",
    "              'n_estimators':[str(n) for n in n_estimators],\n",
    "              'n_jobs':['n_cpu'],\n",
    "              'random_state':['SEED']}\n",
    "\n",
    "    # Create a Custom_GridSearchCV instance\n",
    "    rf_gs = Custom_GridSearchCV('RandomForestClassifier', param_grid=params)\n",
    "else:\n",
    "    with open('rf_gs.pickle', 'rb') as f:\n",
    "        rf_gs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation with recall as the primary scoring\n",
    "rprt, rp_df,_ = rf_gs.cross_validate(X_train_vec, y_train,\n",
    "                                     vectorization=vec_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find training and validation metrics\n",
    "rf_gs_metrics_train,_,_ = prepare_metrics(rf_gs, train_val='train')\n",
    "rf_gs_metrics_valid,_,_ = prepare_metrics(rf_gs, train_val='cross_validate')\n",
    "\n",
    "# Combine metrics \n",
    "rf_gs_metrics = pd.concat([rf_gs_metrics_train,rf_gs_metrics_valid])\n",
    "\n",
    "# Rename dataset as 'dataset_train/validate'\n",
    "rf_gs_metrics.dataset = rf_gs_metrics.dataset+'_'+rf_gs_metrics.train_val\n",
    "\n",
    "# Create a placeholder dataframe to store the average values\n",
    "rf_gs_metrics_mean = pd.DataFrame(columns=rf_gs_metrics.metric.unique(),\n",
    "                                  index=rf_gs_metrics.dataset.unique())\n",
    "\n",
    "# Iterate through each row and column, aggregate values and take the mean\n",
    "for col in rf_gs_metrics_mean.columns:\n",
    "    for idx in rf_gs_metrics_mean.index:\n",
    "        avg = rf_gs_metrics.loc[(rf_gs_metrics.metric==col) & (rf_gs_metrics.dataset==idx),'value']\n",
    "        rf_gs_metrics_mean.loc[idx,col] = avg.mean()\n",
    "\n",
    "# Sort average metrics by recall, AUC and accuracy\n",
    "rf_gs_metrics_mean.sort_values(by=metrics,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the metrics for training and validation datasets\n",
    "plot_metrics(rf_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit grid search models with the best training dataset\n",
    "# Specifying count to have better accuracy values\n",
    "rf_gs.fit(X_train_vec[1], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test and training datasets \n",
    "# Also get the metrics of fit\n",
    "# Check if the models have not been predicted yet \n",
    "if not isinstance(rf_gs.predictions, pd.DataFrame):\n",
    "    prep = Preprocess(transformer='count',max_df=0.979,min_df=0.0201)\n",
    "    rf_gs.predict(prep.transform(X_valid), y_valid, train_test='validate')\n",
    "    rf_gs.predict(X_train_vec[1], y_train, train_test='train')\n",
    "rf_gs.predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove models with recall=1 \n",
    "rf_gs.predictions = rf_gs.predictions.loc[rf_gs.predictions.recall>0]\n",
    "rf_gs.predictions.sort_values(by=['accuracy'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics for predicted values\n",
    "plot_predictions(rf_gs, valid_test='validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model and model metrics based on given metrics \n",
    "best_rf_model, best_rf_model_metrics = rf_gs.best_model(metrics=metrics, \n",
    "                                                        valid_test='validate')\n",
    "\n",
    "# Store best model \n",
    "# best_models.append(best_rf_model)\n",
    "\n",
    "# Store best model metrics \n",
    "# best_models_metrics = pd.DataFrame(best_rf_model_metrics).transpose()\n",
    "\n",
    "# Display best model parameters \n",
    "best_rf_model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best rf model metrics\n",
    "best_rf_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "plot_confusion_matrix(y_valid, best_rf_model_metrics.preds, \n",
    "                      normalize='true');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists('rf_gs.pickle'):\n",
    "    with open('rf_gs.pickle', 'wb') as f:    \n",
    "        pickle.dump(rf_gs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the parameters used for random forest, learning rate is added as a parameter for XGBoost. Also notice that GPU is enabled for XGBoost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the variable exists\n",
    "if not exists('xgb_gs.pickle'):\n",
    "\n",
    "    # Define learning rate range\n",
    "    learning_rate = [0.001,0.01]\n",
    "\n",
    "    # Define min_child_weight range \n",
    "    min_child_weight = np.arange(1, 5, 2)\n",
    "\n",
    "    # Define max_depth range \n",
    "    max_depth = np.arange(5, 10, 2)\n",
    "          \n",
    "    # Define parameters ranges \n",
    "    params = {'learning_rate': [str(l) for l in learning_rate],\n",
    "              'max_depth': ['None']+[str(m) for m in max_depth],\n",
    "              'min_child_weight': ['None']+[str(m) for m in min_child_weight],\n",
    "              'random_state':['SEED'],\n",
    "              'tree_method':[\"'gpu_hist'\"]}\n",
    "\n",
    "    # Create a Custom_GridSearchCV instance\n",
    "    xgb_gs = Custom_GridSearchCV('XGBClassifier', param_grid=params)\n",
    "else:\n",
    "    # Replace xgb_gs by model_cv[5]\n",
    "    with open('xgb_gs.pickle', 'rb') as f:\n",
    "        xgb_gs = pickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation with accuracy as the primary scoring\n",
    "rprt, rp_df,_ = xgb_gs.cross_validate(X_train_vec, y_train, \n",
    "                                      vectorization=vec_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find training and validation metrics\n",
    "xgb_gs_metrics_train,_,_ = prepare_metrics(xgb_gs, train_val='train')\n",
    "xgb_gs_metrics_valid,_,_ = prepare_metrics(xgb_gs, train_val='cross_validate')\n",
    "\n",
    "# Combine metrics \n",
    "xgb_gs_metrics = pd.concat([xgb_gs_metrics_train,xgb_gs_metrics_valid])\n",
    "\n",
    "# Rename dataset as 'dataset_train/validate'\n",
    "xgb_gs_metrics.dataset = xgb_gs_metrics.dataset+'_'+xgb_gs_metrics.train_val\n",
    "\n",
    "# Create a placeholder dataframe to store the average values\n",
    "xgb_gs_metrics_mean = pd.DataFrame(columns=xgb_gs_metrics.metric.unique(),\n",
    "                                  index=xgb_gs_metrics.dataset.unique())\n",
    "\n",
    "# Iterate through each row and column, aggregate values and take the mean\n",
    "for col in xgb_gs_metrics_mean.columns:\n",
    "    for idx in xgb_gs_metrics_mean.index:\n",
    "        avg = xgb_gs_metrics.loc[(xgb_gs_metrics.metric==col) & (xgb_gs_metrics.dataset==idx),'value']\n",
    "        xgb_gs_metrics_mean.loc[idx,col] = avg.mean()\n",
    "        \n",
    "# Sort average metrics by accuracy, recall, and AUC\n",
    "xgb_gs_metrics_mean.sort_values(by=metrics, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly random oversampling is preferable over smote. But XGBoost takes a long time to run. This will be corrected next time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the metrics for training and validation datasets\n",
    "plot_metrics(xgb_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit grid search models with the best training dataset\n",
    "# SMOTE has better accuracy and recall values\n",
    "# Therefore, 'class_weight' is disabled\n",
    "xgb_gs.fit(X_train_vec[0], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test and training datasets \n",
    "# Also get the metrics of fit \n",
    "if not isinstance(xgb_gs.predictions, pd.DataFrame):\n",
    "    prep = Preprocess(transformer='tfidf',max_df=0.979, min_df=0.0201)\n",
    "    tmp = pd.DataFrame(prep.transform(X_valid), columns=xgb_gs.models[0].get_booster().feature_names)\n",
    "    xgb_gs.predict(tmp, y_valid, train_test='validate')\n",
    "    xgb_gs.predict(X_train_vec[0], y_train, train_test='train')\n",
    "xgb_gs.predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics for predicted values\n",
    "plot_predictions(xgb_gs, valid_test='validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model and model metrics based on given metrics \n",
    "best_xgb_model, best_xgb_model_metrics = xgb_gs.best_model(metrics=metrics, \n",
    "                                                           valid_test='validate')\n",
    "\n",
    "# # Store best model \n",
    "# best_models.append(best_xgb_model)\n",
    "\n",
    "# # Store best model metrics \n",
    "# best_xgb_model_metrics = pd.DataFrame(best_xgb_model_metrics).transpose()\n",
    "# best_models_metrics = pd.concat([best_models_metrics,best_xgb_model_metrics],\n",
    "#                                ignore_index=True)\n",
    "\n",
    "# Display best model parameters \n",
    "best_xgb_model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best DT model metrics \n",
    "best_xgb_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "plot_confusion_matrix(y_valid, best_xgb_model_metrics.preds, \n",
    "                      normalize='true');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists('xgb_gs.pickle'):\n",
    "    with open('xgb_gs.pickle', 'wb') as f:    \n",
    "        pickle.dump(xgb_gs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For CatBoost, border count, depth, iterations, l2 leaf regularization and learning rate were used as grid parameters. Similar to XGBoost, `GPU` are also enabled. Class weights were rejected by the model as those parameters needed to be defined along with `fit` function, which were not implemented in the `Custom_GridSearchCV` class.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the variable exists\n",
    "if not exists('cb_gs.pickle'):\n",
    "    \n",
    "    # Define parameters ranges \n",
    "    params = {'border_count':[100,200],\n",
    "              'depth':np.arange(1,11,5),          \n",
    "              'iterations':[500,1000],\n",
    "              'l2_leaf_reg':[10,100],\n",
    "              'learning_rate':[0.001,0.01],\n",
    "              'logging_level':[\"'Silent'\"],\n",
    "              'random_state':['SEED'],\n",
    "              'task_type':[\"'GPU'\"],\n",
    "              'thread_count':['n_cpu']}\n",
    "\n",
    "    # Convert parameters to string \n",
    "    for key in params.keys():\n",
    "        params[key] = [str(p) for p in params[key]]\n",
    "\n",
    "    # Create a Custom_GridSearchCV instance\n",
    "    cb_gs = Custom_GridSearchCV('CatBoostClassifier', param_grid=params)\n",
    "else:\n",
    "    # Replace xgb_gs by model_cv[5]\n",
    "    with open('cb_gs.pickle', 'rb') as f:\n",
    "        cb_gs = pickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation with accuracy as the primary scoring\n",
    "rprt, rp_df,_ = cb_gs.cross_validate(X_train_vec, y_train,\n",
    "                                     vectorization=vec_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find training and validation metrics\n",
    "cb_gs_metrics_train,_,_ = prepare_metrics(cb_gs, train_val='train')\n",
    "cb_gs_metrics_valid,_,_ = prepare_metrics(cb_gs, train_val='cross_validate')\n",
    "\n",
    "# Combine metrics \n",
    "cb_gs_metrics = pd.concat([cb_gs_metrics_train,cb_gs_metrics_valid])\n",
    "\n",
    "# Rename dataset as 'dataset_train/validate'\n",
    "cb_gs_metrics.dataset = cb_gs_metrics.dataset+'_'+cb_gs_metrics.train_val\n",
    "\n",
    "# Create a placeholder dataframe to store the average values\n",
    "cb_gs_metrics_mean = pd.DataFrame(columns=cb_gs_metrics.metric.unique(),\n",
    "                                  index=cb_gs_metrics.dataset.unique())\n",
    "\n",
    "# Iterate through each row and column, aggregate values and take the mean\n",
    "for col in cb_gs_metrics_mean.columns:\n",
    "    for idx in cb_gs_metrics_mean.index:\n",
    "        avg = cb_gs_metrics.loc[(cb_gs_metrics.metric==col) & (cb_gs_metrics.dataset==idx),'value']\n",
    "        cb_gs_metrics_mean.loc[idx,col] = avg.mean()\n",
    "        \n",
    "# Sort average metrics by recall, AUC and accuracy\n",
    "cb_gs_metrics_mean.sort_values(by=metrics,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the metrics for training and validation datasets\n",
    "plot_metrics(cb_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE has the largest good tradeoff between accuracy and recall for the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists('cb_gs_cross_validate.pickle'):\n",
    "    with open('cb_gs_cross_validate.pickle', 'wb') as f:    \n",
    "        pickle.dump(cb_gs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit grid search models with the best training dataset\n",
    "# SMOTE has better accuracy and recall values\n",
    "# Therefore, 'class_weight' is disabled\n",
    "cb_gs.fit(X_train_vec[-1], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test and training datasets \n",
    "# Also get the metrics of fit \n",
    "if not isinstance(cb_gs.predictions, pd.DataFrame):\n",
    "    prep = Preprocess(transformer='embed')\n",
    "    cb_gs.predict(prep.transform(X_valid), y_valid, train_test='validate')\n",
    "    cb_gs.predict(X_train_vec[-1], y_train, train_test='train')\n",
    "cb_gs.predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics for predicted values\n",
    "plot_predictions(cb_gs, valid_test='validate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost appears to have close prediction for training and validation test compared to the other models. This will be quantified later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model and model metrics based on given metrics \n",
    "best_cb_model, best_cb_model_metrics = cb_gs.best_model(metrics=metrics,\n",
    "                                                       valid_test='validate')\n",
    "\n",
    "# # Store best model \n",
    "# best_models.append(best_cb_model)\n",
    "\n",
    "# # Store best model metrics \n",
    "# best_cb_model_metrics = pd.DataFrame(best_cb_model_metrics).transpose()\n",
    "# best_models_metrics = pd.concat([best_models_metrics,best_cb_model_metrics],\n",
    "#                                ignore_index=True)\n",
    "\n",
    "# Display best model parameters \n",
    "best_cb_model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best DT model metrics \n",
    "best_cb_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "plot_confusion_matrix(y_valid, best_cb_model_metrics.preds, \n",
    "                      normalize='true');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models can now be saved to file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists('cb_gs.pickle'):\n",
    "    with open('cb_gs.pickle', 'wb') as f:    \n",
    "        pickle.dump(cb_gs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short Term Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 20000\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "train_texts = tokenizer.texts_to_sequences(X_train)\n",
    "val_texts = tokenizer.texts_to_sequences(X_valid)\n",
    "# test_texts = tokenizer.texts_to_sequences(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = max(len(train_ex) for train_ex in train_texts)\n",
    "train_texts = pad_sequences(train_texts, maxlen=MAX_LENGTH)\n",
    "val_texts = pad_sequences(val_texts, maxlen=MAX_LENGTH)\n",
    "# test_texts = pad_sequences(test_texts, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(embedding=None):    \n",
    "    if embedding is None:\n",
    "        sequences = layers.Input(shape=(MAX_LENGTH,))\n",
    "        embedded = layers.Embedding(MAX_FEATURES, 64)(sequences)\n",
    "    else:\n",
    "        sequences = layers.Input(shape=(embedding.shape[1],))\n",
    "        embedded = layers.Embedding(embedding.shape[0],embedding.shape[1], \n",
    "                                        weights=[embedding_matrix], \n",
    "                                        trainable=False)(sequences)\n",
    "    x = layers.CuDNNLSTM(128, return_sequences=True)(embedded)\n",
    "    x = layers.CuDNNLSTM(128)(x)\n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)    \n",
    "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=sequences, outputs=predictions)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_no_weight = build_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 167)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 167, 64)           1280000   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 167, 128)          99328     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 128)               132096    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,527,589\n",
      "Trainable params: 1,527,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model_no_weight.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19688/19688 [==============================] - 1014s 51ms/step - loss: 0.2366 - accuracy: 0.9030 - val_loss: 0.2085 - val_accuracy: 0.9164\n"
     ]
    }
   ],
   "source": [
    "lstm_model_no_weight.fit(\n",
    "        train_texts, \n",
    "        y_train, \n",
    "        batch_size=128,\n",
    "        epochs=1,\n",
    "        validation_data=(val_texts, y_valid));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lstm_model_no_weight.predict(val_texts)\n",
    "preds = 1 * (preds > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 2.886\n",
      "Accuracy: 0.9164\n",
      "Precision: 0.9074\n",
      "Recall: 0.9275\n",
      "F1: 0.9174\n",
      "ROC AUC: 0.9164\n"
     ]
    }
   ],
   "source": [
    "print('Log loss: {:0.4}'.format(log_loss(y_valid, preds)))\n",
    "print('Accuracy: {:0.4}'.format(accuracy_score(y_valid, preds)))\n",
    "print('Precision: {:0.4}'.format(precision_score(y_valid, preds)))\n",
    "print('Recall: {:0.4}'.format(recall_score(y_valid, preds)))\n",
    "print('F1: {:0.4}'.format(f1_score(y_valid, preds)))\n",
    "print('ROC AUC: {:0.4}'.format(roc_auc_score(y_valid, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_valid, preds, normalize='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us use GloVe word embedding and retrain the model. First, the embedding matrix must be computed based on how many words have been tokenized.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = len(embeddings_index[next(iter(embeddings_index))])\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "train_texts = tokenizer.texts_to_sequences(X_train)\n",
    "val_texts = tokenizer.texts_to_sequences(X_valid)\n",
    "train_texts = pad_sequences(train_texts, maxlen=MAX_LENGTH)\n",
    "val_texts = pad_sequences(val_texts, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((len(word_index)+1, MAX_LENGTH))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_glove = build_lstm_model(embedding=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_glove.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, using word embedding is going to exponentially increase our computation. But for the most part, the embedding layer is set to non-trainable.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_glove.fit(train_texts, \n",
    "                     y_train, \n",
    "                     batch_size=128, \n",
    "                     epochs=1,\n",
    "                     validation_data=(val_texts, y_valid));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lstm_model_glove.predict(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lstm_model_no_weight.predict(val_texts)\n",
    "preds = 1 * (preds > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Log loss: {:0.4}'.format(log_loss(y_valid, preds)))\n",
    "print('Accuracy: {:0.4}'.format(accuracy_score(y_valid, preds)))\n",
    "print('Precision: {:0.4}'.format(precision_score(y_valid, preds)))\n",
    "print('Recall: {:0.4}'.format(recall_score(y_valid, preds)))\n",
    "print('F1: {:0.4}'.format(f1_score(y_valid, preds)))\n",
    "print('ROC AUC: {:0.4}'.format(roc_auc_score(y_valid, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_valid, preds, normalize='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Encoder Representations from Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models' Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Development "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Deployment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
