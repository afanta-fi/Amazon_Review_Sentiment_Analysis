{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Business-Understanding\" data-toc-modified-id=\"Business-Understanding-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Business Understanding</a></span></li><li><span><a href=\"#Data-Understanding\" data-toc-modified-id=\"Data-Understanding-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Understanding</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Preparation</a></span></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Custom-Classes\" data-toc-modified-id=\"Custom-Classes-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Custom Classes</a></span></li><li><span><a href=\"#Shallow-Learning\" data-toc-modified-id=\"Shallow-Learning-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Shallow Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Naive Bayes</a></span></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Logistic Regression</a></span></li></ul></li><li><span><a href=\"#Gradient-Boosting\" data-toc-modified-id=\"Gradient-Boosting-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Gradient Boosting</a></span><ul class=\"toc-item\"><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>XGBoost</a></span></li><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>CatBoost</a></span></li></ul></li><li><span><a href=\"#Sequence-Models\" data-toc-modified-id=\"Sequence-Models-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Sequence Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gated-Recurrent-Unit\" data-toc-modified-id=\"Gated-Recurrent-Unit-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Gated Recurrent Unit</a></span></li><li><span><a href=\"#Long-Short-Term-Memory\" data-toc-modified-id=\"Long-Short-Term-Memory-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Long Short Term Memory</a></span></li></ul></li><li><span><a href=\"#Transformer-Models\" data-toc-modified-id=\"Transformer-Models-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Transformer Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bidirectional-Encoder-Representations-from-Transformers\" data-toc-modified-id=\"Bidirectional-Encoder-Representations-from-Transformers-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>Bidirectional Encoder Representations from Transformers</a></span></li><li><span><a href=\"#Hugging-Face\" data-toc-modified-id=\"Hugging-Face-4.5.2\"><span class=\"toc-item-num\">4.5.2&nbsp;&nbsp;</span>Hugging Face</a></span></li></ul></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Models'-Performances\" data-toc-modified-id=\"Models'-Performances-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Models' Performances</a></span></li><li><span><a href=\"#Final-Model\" data-toc-modified-id=\"Final-Model-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Final Model</a></span></li><li><span><a href=\"#Model-Interpretation\" data-toc-modified-id=\"Model-Interpretation-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Model Interpretation</a></span></li><li><span><a href=\"#API-Development\" data-toc-modified-id=\"API-Development-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>API Development</a></span></li><li><span><a href=\"#Web-Deployment\" data-toc-modified-id=\"Web-Deployment-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Web Deployment</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusion</a></span></li><li><span><a href=\"#Next-Steps\" data-toc-modified-id=\"Next-Steps-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Next Steps</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyenchant \n",
    "# ! pip install autocorrect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import important libraries\n",
    "import wget\n",
    "import zipfile\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import bz2\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "import re \n",
    "from autocorrect import Speller\n",
    "from enchant import request_dict\n",
    "from enchant.checker import SpellChecker\n",
    "from enchant.tokenize import EmailFilter, URLFilter\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.concurrent import process_map \n",
    "from multiprocessing import Pool\n",
    "from time import time\n",
    "from os import remove\n",
    "from os.path import exists\n",
    "import itertools as it\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier \n",
    "from catboost import CatBoostClassifier\n",
    "import shap \n",
    "from sklearn.metrics import precision_score,accuracy_score,recall_score,plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score,roc_auc_score,log_loss,roc_curve,auc,confusion_matrix\n",
    "import dill as pickle\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "from textwrap import wrap\n",
    "\n",
    "\n",
    "# Enable inline ploting\n",
    "%matplotlib inline \n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\zeaps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zeaps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zeaps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 100%|██████████| 3600000/3600000 [00:03<00:00, 1061260.94it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_data(b2z_file_loc):\n",
    "    file = bz2.BZ2File(b2z_file_loc)\n",
    "    t = tqdm(file.readlines())\n",
    "    t.set_description('Loading '+b2z_file_loc.split('/')[-1].split('.')[0]+' data')\n",
    "    return [x.decode('utf-8') for x in t]\n",
    "        \n",
    "train_file_lines = load_data('data/train.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n',\n",
       " \"__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\\n\",\n",
       " '__label__2 Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\\n',\n",
       " \"__label__2 Excellent Soundtrack: I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\\n\",\n",
       " \"__label__2 Remember, Pull Your Jaw Off The Floor After Hearing it: If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\\n\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"__label__1 The Worst!: A complete waste of time. Typographical errors, poor grammar, and a totally pathetic plot add up to absolutely nothing. I'm embarrassed for this author and very disappointed I actually paid for this book.\\n\",\n",
       " '__label__2 Great book: This was a great book,I just could not put it down,and could not read it fast enough. Boy what a book the twist and turns in this just keeps you guessing and wanting to know what is going to happen next. This book makes you fall in love and can heat you up,it can also make you so angery. this book can make you go throu several of your emotions. This is a quick read romance. It is something that you will want to end your day off with if you read at night.\\n',\n",
       " '__label__2 Great Read: I thought this book was brilliant, but yet realistic. It showed me that to error is human. I loved the fact that this writer showed the loving side of God and not the revengeful side of him. I loved how it twisted and turned and I could not put it down. I also loved The glass castle.\\n',\n",
       " \"__label__1 Oh please: I guess you have to be a romance novel lover for this one, and not a very discerning one. All others beware! It is absolute drivel. I figured I was in trouble when a typo is prominently featured on the back cover, but the first page of the book removed all doubt. Wait - maybe I'm missing the point. A quick re-read of the beginning now makes it clear. This has to be an intentional churning of over-heated prose for satiric purposes. Phew, so glad I didn't waste $10.95 after all.\\n\",\n",
       " '__label__1 Awful beyond belief!: I feel I have to write to keep others from wasting their money. This book seems to have been written by a 7th grader with poor grammatical skills for her age! As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. For example, it was mentioned twice that she had a \"lean\" on her house. I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. Please don\\'t waste your money. I too, believe that the good reviews must have been written by the author\\'s relatives. I will not put much faith in the reviews from now on!\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_lines[10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Translate nltk POS to wordnet tags\n",
    "    '''\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkr = SpellChecker(\"en_US\",filters=[EmailFilter,URLFilter])\n",
    "spell = Speller(lang='en')\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "tokenizer = RegexpTokenizer(pattern)\n",
    "sw = stopwords.words('english')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def data_cleaner(data, labeled=True):\n",
    "    splits = data.split('__label__')[-1]\n",
    "    if labeled:\n",
    "        labels = int(splits[0])-1    \n",
    "        statement = decontracted(splits[1:].lower())\n",
    "    else:\n",
    "        labels = np.nan\n",
    "        statement = decontracted(splits.lower())\n",
    "    statement = spell(statement)\n",
    "    chkr.set_text(statement)\n",
    "    for err in chkr:\n",
    "        try:            \n",
    "            statement = statement.replace(err.word,request_dict(err.word)[0])\n",
    "        except:\n",
    "            continue\n",
    "    statement = tokenizer.tokenize(statement)        \n",
    "    statement = [w for w in statement if w not in sw]\n",
    "    statement_tagged = [(token[0], get_wordnet_pos(token[1]))\n",
    "                        for token in pos_tag(statement)]\n",
    "    statement_lemmed = [lemmatizer.lemmatize(token[0], token[1]) for token in statement_tagged]\n",
    "    return statement_lemmed, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tune',\n",
       " 'even',\n",
       " 'non',\n",
       " 'gamer',\n",
       " 'sound',\n",
       " 'track',\n",
       " 'beautiful',\n",
       " 'paint',\n",
       " 'scenery',\n",
       " 'mind',\n",
       " 'well',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'even',\n",
       " 'people',\n",
       " 'hate',\n",
       " 'vid',\n",
       " 'game',\n",
       " 'music',\n",
       " 'play',\n",
       " 'game',\n",
       " 'chrono',\n",
       " 'cross',\n",
       " 'game',\n",
       " 'ever',\n",
       " 'play',\n",
       " 'best',\n",
       " 'music',\n",
       " 'back',\n",
       " 'away',\n",
       " 'crude',\n",
       " 'keyboardist',\n",
       " 'take',\n",
       " 'fresh',\n",
       " 'step',\n",
       " 'rate',\n",
       " 'guitar',\n",
       " 'soulful',\n",
       " 'orchestra',\n",
       " 'would',\n",
       " 'impress',\n",
       " 'anyone',\n",
       " 'care',\n",
       " 'listen']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement, labels = data_cleaner(train_file_lines[0])\n",
    "statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(file_lines, attrib):\n",
    "    currtime = time()\n",
    "    results = process_map(data_cleaner, file_lines, \n",
    "                          max_workers=Pool()._processes, \n",
    "                          chunksize=Pool()._processes)\n",
    "    statements = []\n",
    "    labels = []\n",
    "    for result in results:\n",
    "        statements.append(result[0])\n",
    "        labels.append(result[-1])\n",
    "    df = pd.DataFrame(columns=['statements','labels'])\n",
    "    df.statements = statements\n",
    "    df.labels = labels\n",
    "    df.to_csv(r'data/'+attrib+'.zip', index=False, compression='gzip')\n",
    "    print('Parallel: time elapsed:', time() - currtime)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists('data/train.zip'):\n",
    "    del train_file_lines\n",
    "    train_df = pd.read_csv('data/train.zip', compression='gzip')\n",
    "    def str_cleaner(line):\n",
    "        return line[1:-1].replace(\"'\",'').replace(' ','').replace(',',' ')\n",
    "    train_df.statements = train_df.statements.apply(str_cleaner)\n",
    "else:\n",
    "    train_df = save_to_file(train_file_lines, 'train') \n",
    "    del train_file_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statements</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tune even non gamer sound track beautiful pain...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best soundtrack ever anything reading lot revi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amaze soundtrack favorite music time hand inte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excellent soundtrack truly like soundtrack enj...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remember pull jaw floor hear played game know ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          statements  labels\n",
       "0  tune even non gamer sound track beautiful pain...       1\n",
       "1  best soundtrack ever anything reading lot revi...       1\n",
       "2  amaze soundtrack favorite music time hand inte...       1\n",
       "3  excellent soundtrack truly like soundtrack enj...       1\n",
       "4  remember pull jaw floor hear played game know ...       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.labels.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists('glove.6B.300d.txt'):\n",
    "    wget.download(url='https://nlp.stanford.edu/data/glove.6B.zip')\n",
    "    zip_ = zipfile.ZipFile('glove.6B.zip')\n",
    "    zip_.extract('glove.6B.300d.txt')    \n",
    "    zip_.close()    \n",
    "    remove('glove.6B.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'book': 644792, 'one': 415217, 'good': 340365, 'like': 335654, 'get': 332100, 'great': 317340, 'movie': 291664, 'would': 282641, 'read': 275493, 'time': 246530, ...})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = FreqDist(tokenizer.tokenize(' '.join(train_df.statements[:1000000].to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.6B.300d.txt', encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df.statements, \n",
    "                                                      train_df.labels,\n",
    "                                                      random_state=SEED, \n",
    "                                                      stratify = train_df.labels,\n",
    "                                                      test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 1.0}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use compute_class_weight to compute the class weight. \n",
    "# Balanced is used to match results with oversampled data. \n",
    "class_weights = compute_class_weight(class_weight = \"balanced\",\n",
    "                                     classes = np.unique(y_train),\n",
    "                                     y = y_train)\n",
    "# class_weights is changed into a dictionary for better handling\n",
    "class_weights = dict(zip(np.unique(y_train), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700000,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "    def __init__(self, dataset=None, \n",
    "                 transformer='tfidf', \n",
    "                 cleaned=True, \n",
    "                 ngram_range=(1,1),\n",
    "                 max_features = 20000,\n",
    "                 min_df = 0.05, \n",
    "                 max_df = 0.95):\n",
    "        self.dataset = dataset\n",
    "        self.transformer = transformer\n",
    "        self.cleaned = cleaned\n",
    "        self.ngram_range = ngram_range\n",
    "        self.max_features = max_features\n",
    "        self.min_df = min_df\n",
    "        self.max_df = max_df\n",
    "    \n",
    "    def load_data(self, n_pool, labeled, attrib):\n",
    "        if not self.cleaned:\n",
    "            statements = []\n",
    "            labels = []\n",
    "            if n_pool==1:\n",
    "                for data in self.dataset:\n",
    "                    statement, label = data_cleaner(data)\n",
    "                    statements.append(statement)\n",
    "                    labels.append(label)\n",
    "            else:\n",
    "                results = process_map(data_cleaner, data, \n",
    "                          max_workers=n_pool, \n",
    "                          chunksize=n_pool)\n",
    "                for result in results:\n",
    "                    statements.append(result[0])\n",
    "                    labels.append(result[-1])\n",
    "            df = pd.DataFrame(columns=['statements','labels'])\n",
    "            df.statements = statements\n",
    "            df.labels = labels\n",
    "            df.to_csv(r'data/'+attrib+'.zip', index=False, compression='gzip')            \n",
    "        else:\n",
    "            df = pd.read_csv('data/'+attrib+'.zip', compression='gzip')\n",
    "            def str_cleaner(line):\n",
    "                return line[1:-1].replace(\"'\",'').replace(' ','').replace(',',' ')\n",
    "            df.statements = df.statements.apply(str_cleaner)\n",
    "        return df\n",
    "    \n",
    "    def transform(self, df):\n",
    "        if self.transformer=='tfidf':\n",
    "            vectorizer = TfidfVectorizer(max_features=self.max_features, \n",
    "                                         ngram_range=self.ngram_range,\n",
    "                                         min_df=self.min_df,\n",
    "                                         max_df=self.max_df)\n",
    "            tokens = vectorizer.fit_transform(df).toarray()\n",
    "        elif self.transformer=='count':\n",
    "            vectorizer = CountVectorizer(max_features=self.max_features, \n",
    "                                         ngram_range=self.ngram_range,\n",
    "                                         min_df=self.min_df,\n",
    "                                         max_df=self.max_df)\n",
    "            tokens = vectorizer.fit_transform(df).toarray()\n",
    "        elif self.transformer=='embed':\n",
    "            def sent2vec(s):\n",
    "                M = []\n",
    "                for w in s:\n",
    "                    try:\n",
    "                        M.append(embeddings_index[w])\n",
    "                    except:\n",
    "                        continue\n",
    "                M = np.array(M)\n",
    "                v = M.sum(axis=0)\n",
    "                if type(v) != np.ndarray:\n",
    "                    return np.zeros(300)\n",
    "                return v / np.sqrt((v ** 2).sum())\n",
    "            data = df.apply(word_tokenize)\n",
    "            tokens = np.array(data.apply(sent2vec).tolist())\n",
    "        return tokens        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 91)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = Preprocess(transformer='tfidf')\n",
    "prep.transform(train_df.statements[:100000]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700000, 92)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = Preprocess(transformer='tfidf')\n",
    "test = prep.transform(X_train)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000, 92)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = Preprocess(transformer='tfidf')\n",
    "prep.transform(X_valid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_GridSearchCV():\n",
    "    def __init__(self, estimator, param_grid={}, cv=5):\n",
    "        \"\"\"\n",
    "        Custom_GridSearchCV: A grid search that automatically returns\n",
    "        various metrics for almost all sklearn, xgboost and catboost \n",
    "        classification models.\n",
    "        estimator: A string of the model\n",
    "        param_grid: parametric grid for grid search. All entries should be in \n",
    "        string format\n",
    "        cv: Number of cross validation folds \n",
    "        \"\"\"\n",
    "        # Initialize cv\n",
    "        self.cv = cv \n",
    "        # Initialize fitted, boolean if the grid of models have been fitted\n",
    "        self.fitted = False \n",
    "        # Initialize models list\n",
    "        self.models = []\n",
    "        # Initialize cross validation evaluations \n",
    "        self.cross_eval = {}\n",
    "        # Extract parameters for baseline model. Parameters with only one value\n",
    "        # are selected.\n",
    "        base_params = [k+\"=\"+v[0] for k,v in param_grid.items() if len(v)==1]\n",
    "        base_params = ','.join(base_params)\n",
    "        # Initialize baseline model \n",
    "        exec(\"self.baseline_model = \"+estimator+\"(\"+base_params+\")\")\n",
    "        # Create a combinations of the parameter grid \n",
    "        all_params = sorted(param_grid)\n",
    "        combinations = it.product(*(param_grid[name] for name in all_params))\n",
    "        # Iterate through the combinations and keys to create a list of models\n",
    "        keys = list(param_grid.keys())\n",
    "        for j, comb in enumerate(combinations):\n",
    "            params = \"\"\n",
    "            for i, key in enumerate(keys):\n",
    "                params += key+\"=\"+comb[i]+\",\"\n",
    "            # Append models \n",
    "            exec(\"self.models.append(\"+estimator+\"(\"+params[:-1]+\"))\")\n",
    "        # Initialize predictions dataframe\n",
    "        self.predictions = None\n",
    "            \n",
    "    def cross_validate(self, X, y, scoring=\"accuracy\"):\n",
    "        \"\"\"\n",
    "        Cross validate data on training data and return dataset with the \n",
    "        largest scoring.\n",
    "        X: Training dataset \n",
    "        y: Training labels \n",
    "        scoring: The type of scoring used in cross validation. Valid entries \n",
    "        are 'accuracy','precision','recall','f1' and 'roc_auc' \n",
    "        \"\"\"\n",
    "        # Set default scoring \n",
    "        self.scoring = scoring\n",
    "        # Weighted boolean\n",
    "        weighted = False\n",
    "        # Cross validation: run custom_cross_validate with class weights, \n",
    "        # and over-sampled data with SMOTE, ADASYN and Random Over Sampler  \n",
    "        if self.cross_eval=={}:\n",
    "            cross_eval_dataset = [\"class_weight\"]\n",
    "            for sample in cross_eval_dataset:\n",
    "                # Check if the estimator has 'class_weight' attribute\n",
    "                if sample==\"class_weight\":                    \n",
    "                    # Clone the baseline model and assign class weight\n",
    "                    bl_model = clone(self.baseline_model)\n",
    "                    if hasattr(self.baseline_model, sample): \n",
    "                        bl_model.class_weight = class_weights\n",
    "                        weighted = True\n",
    "                    # XGBoost exceptions \n",
    "                    elif hasattr(self.baseline_model, 'scale_pos_weight'):\n",
    "                        weight = class_weights[1]/class_weights[0]\n",
    "                        bl_model.scale_pos_weight = weight\n",
    "                        weighted = True  \n",
    "                    # CatBoost exceptions \n",
    "                    elif hasattr(self.baseline_model, \"class_weights\"):\n",
    "                        bl_model.class_weights = class_weights\n",
    "                        weighted = True                        \n",
    "                    if weighted: \n",
    "                        # Run custom cross validation \n",
    "                        train_dict, valid_dict = custom_cross_validate(bl_model, \n",
    "                                                                   X,\n",
    "                                                                   y, \n",
    "                                                                   sample, \n",
    "                                                                   cv=self.cv)\n",
    "                        # Append values \n",
    "                        self.cross_eval[sample] = {'train':train_dict,\n",
    "                                                  'validate':valid_dict}\n",
    "                        \n",
    "                else:\n",
    "                    # Run custom cross validate on over-sampled data  \n",
    "                    train_dict, valid_dict = custom_cross_validate(self.baseline_model, \n",
    "                                                                   X,\n",
    "                                                                   y, \n",
    "                                                                   sample, \n",
    "                                                                   cv=self.cv)\n",
    "                    # Append values \n",
    "                    self.cross_eval[sample] = {'train':train_dict,\n",
    "                                               'validate':valid_dict} \n",
    "        # 'return_report' returns values from 'cross_eval' and 'scoring' \n",
    "        return_report = {}        \n",
    "        for dataset in self.cross_eval.keys():\n",
    "            return_report[dataset] = {}\n",
    "            for report in self.cross_eval[dataset].keys():\n",
    "                return_report[dataset][report] = self.cross_eval[dataset][report][scoring]                \n",
    "        # 'report_dataframe': a dataframe where average values are selected\n",
    "        report_dataframe = pd.DataFrame(return_report).applymap(np.mean) \n",
    "        # Transpose the dataframe so that indices represent 'cross_eval_dataset' \n",
    "        report_dataframe = report_dataframe.transpose()\n",
    "        # Select the dataset with maximum score for training \n",
    "        max_train = report_dataframe.train.max()        \n",
    "        max_train_score_dataset = report_dataframe.train[report_dataframe.train==max_train].index\n",
    "        max_train_score_dataset = max_train_score_dataset[0]\n",
    "        # Select the dataset with maximum score for validation \n",
    "        max_valid = report_dataframe.validate.max()        \n",
    "        max_valid_score_dataset = report_dataframe.validate[report_dataframe.validate==max_valid].index\n",
    "        max_valid_score_dataset = max_valid_score_dataset[0]\n",
    "        # Combine scores\n",
    "        max_score_dataset = {'train':max_train_score_dataset,\n",
    "                            'validate':max_valid_score_dataset}\n",
    "        # Return 'return_report' dictionary, 'report_dataframe' dataframe and \n",
    "        # 'max_score_dataset' dataset string\n",
    "        return return_report, report_dataframe, max_score_dataset  \n",
    "        \n",
    "    def fit(self, X, y, class_weight=False):\n",
    "        \"\"\"\n",
    "        Fit training data to a grid of models. \n",
    "        X: Training dataset \n",
    "        y: Training labels \n",
    "        \"\"\"\n",
    "        # Run if models are not fitted\n",
    "        if not self.fitted:\n",
    "            for model in self.models:\n",
    "                if class_weight:\n",
    "                    model.class_weight = class_weights\n",
    "                # Iterate through each model and fit training data\n",
    "                model.fit(X, y)\n",
    "            # Set 'fitted' to True     \n",
    "            self.fitted = True            \n",
    "            \n",
    "    def predict(self, X, y, train_test='test'):\n",
    "        \"\"\"\n",
    "        Predict values: Unlike predict functions for sklearn estimators, \n",
    "        this function takes y value as well, to report fitting metrics \n",
    "        X: Training/test dataset \n",
    "        y: Training/test labels \n",
    "        train_test: only 'train' and 'test' values need to be specified.\n",
    "        \"\"\"\n",
    "        # Dataframe to store prediction per 'train_test'\n",
    "        tr_ts = None\n",
    "        # Iterate through each model             \n",
    "        for model in self.models:\n",
    "            # Calculate predictions\n",
    "            preds = model.predict(X)\n",
    "            # Calculate the probabilities of predictions \n",
    "            prob_preds = model.predict_proba(X)\n",
    "            # Check if the model has 'decision_function'\n",
    "            if hasattr(model,'decision_function'):\n",
    "                score = model.decision_function(X)\n",
    "            else:\n",
    "                # Select scores for roc_curve calculation\n",
    "                score = prob_preds[:, 1]\n",
    "            # Find fpr and tpr values\n",
    "            fpr, tpr, threshold = roc_curve(y, score)\n",
    "            # Dict to store values \n",
    "            tmp = {}\n",
    "            # Populate 'tmp_df' with values\n",
    "            tmp['train_test'] = train_test\n",
    "            tmp['preds'] = [preds]\n",
    "            tmp['prob_preds'] = [prob_preds]\n",
    "            tmp['log_loss_score'] = log_loss(y, preds)\n",
    "            tmp['accuracy'] = accuracy_score(y, preds)\n",
    "            tmp['precision'] = precision_score(y, preds)\n",
    "            tmp['recall'] = recall_score(y, preds)\n",
    "            tmp['f1'] = f1_score(y, preds)\n",
    "            tmp['fpr'] = [fpr]\n",
    "            tmp['tpr'] = [tpr]\n",
    "            tmp['auc'] = auc(fpr, tpr)\n",
    "            tmp['roc_auc'] = roc_auc_score(y, preds)\n",
    "            # Create a temp dataframe with 'predictions' columns\n",
    "            tmp_df = pd.DataFrame(tmp)                \n",
    "            # Concatenate 'tmp_df' and 'tmp_df'\n",
    "            if not isinstance(tr_ts, pd.DataFrame): \n",
    "                tr_ts = tmp_df.copy()\n",
    "            else:\n",
    "                tr_ts = pd.concat([tr_ts,tmp_df])\n",
    "        # Reset indices \n",
    "        tr_ts.index = np.arange(len(self.models))\n",
    "        # Assign values to 'predictions'\n",
    "        if not isinstance(self.predictions, pd.DataFrame):\n",
    "            self.predictions = tr_ts.copy()\n",
    "        else:\n",
    "            self.predictions = pd.concat([self.predictions,tr_ts])\n",
    "    \n",
    "    def best_model(self, metrics=['accuracy']):\n",
    "        \"\"\"\n",
    "        This function returns the best model and model metrics \n",
    "        based on provided metrics from the test dataset.\n",
    "        metrics: A list of metrics\n",
    "        \"\"\"\n",
    "        # Select test cases only \n",
    "        test_metrics = self.predictions.loc[self.predictions.train_test=='test']\n",
    "        # Sort test_metrics by metrics in descending order          \n",
    "        test_metrics = test_metrics.sort_values(by=metrics, ascending=False)\n",
    "        # Reset indices  \n",
    "        test_metrics = test_metrics.reset_index()\n",
    "        # Best model index \n",
    "        idx = test_metrics.loc[0,:]['index']\n",
    "        # Return best model and best model metrics\n",
    "        return self.models[idx], test_metrics.loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_validate(estimator, X, y, over_sample, cv=5):\n",
    "    \"\"\"\n",
    "    'custom_cross_validate' function that performs oversampling and cross \n",
    "    validate results.\n",
    "    X: Training dataset \n",
    "    y: Training labels\n",
    "    over_sample: Type of oversampling method used. Acceptable values are \n",
    "    'class_weight', 'smote', 'adasyn' and 'rand'\n",
    "    cv: The number of cross-validation folds \n",
    "    \"\"\"\n",
    "    # Create dictionaries to hold the scores from each fold\n",
    "    train_dict = {'log_loss_score':np.ndarray(cv), 'precision':np.ndarray(cv), \n",
    "                 'accuracy':np.ndarray(cv), 'recall':np.ndarray(cv), \n",
    "                  'f1':np.ndarray(cv),'fpr':[],\n",
    "                  'tpr':[], 'auc':np.ndarray(cv), 'roc_auc':np.ndarray(cv)\n",
    "                 }\n",
    "    valid_dict = {'log_loss_score':np.ndarray(cv), 'precision':np.ndarray(cv), \n",
    "                 'accuracy':np.ndarray(cv), 'recall':np.ndarray(cv), \n",
    "                  'f1':np.ndarray(cv),'fpr':[],\n",
    "                  'tpr':[], 'auc':np.ndarray(cv), 'roc_auc':np.ndarray(cv)\n",
    "                 }\n",
    "    \n",
    "    # Instantiate a splitter object and loop over its result\n",
    "    kfold = StratifiedKFold(n_splits=cv, shuffle=True)\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X, y)):\n",
    "        # Extract train and validation subsets using the provided indices\n",
    "        X_t, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_t, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        # Instantiate StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        # Fit and transform X_t\n",
    "        X_t_scaled = scaler.fit_transform(X_t)\n",
    "        # Transform X_val\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        \n",
    "        # If over_sample is define, choose the method passed\n",
    "        if over_sample == \"class_weight\":\n",
    "            X_t_oversampled, y_t_oversampled = (X_t_scaled, y_t)            \n",
    "        else:        \n",
    "            if over_sample == \"smote\":\n",
    "                # Instantiate SMOTE \n",
    "                sampler = SMOTE(random_state=SEED)\n",
    "            elif over_sample == \"adasyn\":\n",
    "                # Instantiate ADASYN \n",
    "                sampler = ADASYN(random_state=SEED)\n",
    "            elif over_sample == \"rand\":\n",
    "                # Instantiate RandomOverSampler\n",
    "                sampler = RandomOverSampler(random_state=SEED)\n",
    "            # Fit and transform X_t_scaled and y_t using sm\n",
    "            X_t_oversampled, y_t_oversampled = sampler.fit_resample(X_t_scaled, y_t)\n",
    "        \n",
    "        # Clone the provided model and fit it on the train subset\n",
    "        temp_model = clone(estimator)\n",
    "\n",
    "        # Fit the model \n",
    "        temp_model.fit(X_t_oversampled, y_t_oversampled)\n",
    "        \n",
    "        # Check if the mode has 'decision_function' attribute\n",
    "        if hasattr(temp_model, 'decision_function'):\n",
    "            train_score = temp_model.decision_function(X_t_oversampled)\n",
    "            val_score = temp_model.decision_function(X_val_scaled)\n",
    "        else:        \n",
    "            # Calculate probablities \n",
    "            train_score = temp_model.predict_proba(X_t_oversampled)[:,1]\n",
    "            val_score = temp_model.predict_proba(X_val_scaled)[:,1]\n",
    "                \n",
    "        # Find predictions \n",
    "        train_pred = temp_model.predict(X_t_oversampled)\n",
    "        val_pred = temp_model.predict(X_val_scaled)\n",
    "        # Evaluate the provided model on the train and validation subsets\n",
    "        # Log loss score \n",
    "        train_dict['log_loss_score'][fold] = log_loss(y_t_oversampled, train_pred)\n",
    "        valid_dict['log_loss_score'][fold] = log_loss(y_val, val_pred)\n",
    "        # Accuracy score \n",
    "        train_dict['accuracy'][fold] = accuracy_score(y_t_oversampled, train_pred)\n",
    "        valid_dict['accuracy'][fold] = accuracy_score(y_val, val_pred)\n",
    "        # Precision score \n",
    "        train_dict['precision'][fold] = precision_score(y_t_oversampled, train_pred)\n",
    "        valid_dict['precision'][fold] = precision_score(y_val, val_pred)\n",
    "        # Recall score\n",
    "        train_dict['recall'][fold] = recall_score(y_t_oversampled, train_pred)\n",
    "        valid_dict['recall'][fold] = recall_score(y_val, val_pred)\n",
    "        # F1 score \n",
    "        train_dict['f1'][fold] = f1_score(y_t_oversampled, train_pred)\n",
    "        valid_dict['f1'][fold] = f1_score(y_val, val_pred)\n",
    "        # FPR and TPR \n",
    "        train_fpr, train_tpr, threshold = roc_curve(y_t_oversampled, train_score)\n",
    "        valid_fpr, valid_tpr, threshold = roc_curve(y_val, val_score)\n",
    "        train_dict['fpr'].append(train_fpr)\n",
    "        train_dict['tpr'].append(train_tpr)\n",
    "        valid_dict['fpr'].append(valid_fpr)\n",
    "        valid_dict['tpr'].append(valid_tpr)\n",
    "        # AUC\n",
    "        train_dict['auc'][fold] = auc(train_fpr, train_tpr)\n",
    "        valid_dict['auc'][fold] = auc(valid_fpr, valid_tpr)\n",
    "        # ROC_AUC \n",
    "        train_dict['roc_auc'][fold] = roc_auc_score(y_t_oversampled, train_pred)\n",
    "        valid_dict['roc_auc'][fold] = roc_auc_score(y_val, val_pred)\n",
    "        \n",
    "    # Return training and validation results\n",
    "    return train_dict, valid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regularization range \n",
    "C = np.linspace(0.1, 1, 2)\n",
    "\n",
    "# Define parameters ranges \n",
    "params = {'C':[str(s) for s in C],\n",
    "          'fit_intercept':['False','True'],\n",
    "          'max_iter':['1e3'],\n",
    "          'penalty':[\"'l1'\",\"'l2'\"],\n",
    "          'solver':[\"'liblinear'\"]}\n",
    "\n",
    "# Create a Custom_GridSearchCV instance\n",
    "logreg_gs = Custom_GridSearchCV('LogisticRegression', param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprt, rp_df, best_dataset = logreg_gs.cross_validate(pd.DataFrame(test), y_train, \n",
    "                                                     scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>validate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>0.743912</td>\n",
       "      <td>0.743834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 train  validate\n",
       "class_weight  0.743912  0.743834"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gated Recurrent Unit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short Term Memory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Encoder Representations from Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models' Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Development "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Deployment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
